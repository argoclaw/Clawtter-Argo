#!/usr/bin/env python3
import argparse
"""
Clawtter è‡ªä¸»æ€è€ƒè€…
æ¯å°æ—¶æ ¹æ®å¿ƒæƒ…çŠ¶æ€è‡ªåŠ¨ç”Ÿæˆå¹¶å‘å¸ƒæ¨æ–‡åˆ° Clawtter
"""
import os
os.environ['TZ'] = 'Asia/Tokyo'

import json
import random
import re
import subprocess
import time
from datetime import datetime, timedelta
import requests
import requests
from pathlib import Path
import sys
from pathlib import Path
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ä¸­ä»¥æ”¯æŒæ¨¡å—å¯¼å…¥
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))

# ä»æ ¸å¿ƒå±‚å’Œå·¥å…·å±‚å¯¼å…¥
from core.utils_security import load_config, resolve_path, desensitize_text

# åŠ è½½å®‰å…¨é…ç½®
SEC_CONFIG = load_config()

# æ•æ„Ÿè¯å®šä¹‰(å…¨å±€)
SENSITIVE_KEYWORDS = [
    "éªŒè¯ç ", "verification code", "verification_code",
    "å¯†é’¥", "api key", "apikey", "secret", "credential",
    "claim", "token", "password", "å¯†ç ", "scuttle"
]

# å…´è¶£æ¼‚ç§»é…ç½®
INTEREST_STATE_FILE = "/home/opc/.openclaw/workspace/memory/interest-drift.json"
INTEREST_DECAY = 0.90
INTEREST_BOOST = 0.20
INTEREST_MAX = 2.5
INTEREST_MIN = 0.5

def _normalize_interest_list(items):
    return [i.strip().lower() for i in items if isinstance(i, str) and i.strip()]

def localize_twitter_date(date_str):
    """
    å°† Twitter åŸç”Ÿçš„ UTC æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸œäº¬æœ¬åœ°æ—¶é—´ (+0900)
    è¾“å…¥æ ¼å¼: "Sat Feb 07 08:59:17 +0000 2026"
    è¾“å‡ºæ ¼å¼: "Sat Feb 07 17:59:17 +0900 2026"
    """
    if not date_str:
        return ""
    from datetime import datetime, timezone, timedelta
    try:
        # Twitter æ ¼å¼: "Sat Feb 07 08:59:17 +0000 2026"
        # ä½¿ç”¨ %z è‡ªåŠ¨è§£æ +0000 è¿™ç§æ—¶åŒºåç§»
        dt_utc = datetime.strptime(date_str, "%a %b %d %H:%M:%S %z %Y")
        # è½¬æ¢ä¸ºæœ¬åœ°æ—¶é—´ (JST, +0900)
        dt_jst = dt_utc.astimezone(timezone(timedelta(hours=9)))
        # è¿”å›æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²,æ­¤æ—¶ %z ä¼šå˜æˆ +0900
        return dt_jst.strftime("%a %b %d %H:%M:%S %z %Y")
    except Exception as e:
        print(f"Date conversion failed: {e}")
        return date_str

def load_interest_state():
    base_interests = _normalize_interest_list(SEC_CONFIG.get("interests", []))
    state = {
        "updated": time.time(),
        "weights": {k: 1.0 for k in base_interests}
    }
    if os.path.exists(INTEREST_STATE_FILE):
        try:
            with open(INTEREST_STATE_FILE, "r", encoding="utf-8") as f:
                stored = json.load(f)
            weights = stored.get("weights", {})
            # merge with base interests
            merged = {k: float(weights.get(k, 1.0)) for k in base_interests}
            state["weights"] = merged
            state["updated"] = stored.get("updated", state["updated"])
        except Exception:
            pass
    return state

def save_interest_state(state):
    try:
        os.makedirs(os.path.dirname(INTEREST_STATE_FILE), exist_ok=True)
        with open(INTEREST_STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
    except Exception:
        pass

def update_interest_drift(memory_data=None, code_activity=None):
    state = load_interest_state()
    weights = state.get("weights", {})
    if not weights:
        return []

    text_parts = []
    if memory_data:
        for m in memory_data:
            text_parts.append(m.get("content", ""))
    if code_activity:
        for p in code_activity:
            commits = "; ".join(p.get("commits", [])[:5])
            if commits:
                text_parts.append(commits)

    text = " ".join(text_parts).lower()

    for key, weight in list(weights.items()):
        mentions = text.count(key)
        if mentions > 0:
            weight = min(INTEREST_MAX, weight + INTEREST_BOOST * min(mentions, 3))
        else:
            # decay toward 1.0
            weight = weight * INTEREST_DECAY + (1 - INTEREST_DECAY) * 1.0
        weights[key] = max(INTEREST_MIN, weight)

    state["weights"] = weights
    state["updated"] = time.time()
    save_interest_state(state)

    ranked = sorted(weights.items(), key=lambda x: x[1], reverse=True)
    return [k for k, _ in ranked]

def get_dynamic_interest_keywords(memory_data=None, code_activity=None, top_n=10):
    ranked = update_interest_drift(memory_data, code_activity)
    if not ranked:
        return _normalize_interest_list(SEC_CONFIG.get("interests", []))
    return ranked[:top_n]

def load_recent_memory():
    """åŠ è½½æœ€è¿‘çš„å¯¹è¯å’Œäº‹ä»¶è®°å¿†"""
    memory_files = []

    # å°è¯•åŠ è½½ä»Šå¤©çš„è®°å¿†
    memory_dir = resolve_path(SEC_CONFIG["paths"].get("memory_dir", "~/.openclaw/workspace/memory"))
    today_file = memory_dir / f"{datetime.now().strftime('%Y-%m-%d')}.md"
    if os.path.exists(today_file):
        with open(today_file, 'r', encoding='utf-8') as f:
            content = f.read()
            memory_files.append({
                'date': datetime.now().strftime("%Y-%m-%d"),
                'content': content
            })

    # å°è¯•åŠ è½½æ˜¨å¤©çš„è®°å¿†
    from datetime import timedelta
    yesterday = datetime.now() - timedelta(days=1)
    yesterday_file = memory_dir / f"{yesterday.strftime('%Y-%m-%d')}.md"
    if os.path.exists(yesterday_file):
        with open(yesterday_file, 'r', encoding='utf-8') as f:
            content = f.read()
            memory_files.append({
                'date': yesterday.strftime("%Y-%m-%d"),
                'content': content
            })

    return memory_files

def get_system_introspection():
    """è·å–ç³»ç»Ÿè¿è¡ŒçŠ¶æ€"""
    stats = {}
    try:
        # è´Ÿè½½
        uptime = subprocess.check_output(['uptime'], text=True).strip()
        stats['uptime'] = uptime

        # è´Ÿè½½æ•°å€¼ (1, 5, 15 min)
        load = os.getloadavg()
        stats['load'] = load

        # å†…å­˜
        free = subprocess.check_output(['free', '-m'], text=True).splitlines()
        mem_line = free[1].split()
        stats['mem_used_mb'] = int(mem_line[2])
        stats['mem_total_mb'] = int(mem_line[1])
        stats['mem_percent'] = round(stats['mem_used_mb'] / stats['mem_total_mb'] * 100, 1)

        # ç£ç›˜
        df = subprocess.check_output(['df', '-h', '/'], text=True).splitlines()[1].split()
        stats['disk_percent'] = df[4].rstrip('%')

        # æ—¶é—´æ„Ÿ
        now = datetime.now()
        stats['hour'] = now.hour
        stats['is_weekend'] = now.weekday() >= 5

    except Exception as e:
        stats['error'] = str(e)
    return stats

def get_human_activity_echo():
    """é€šè¿‡æ–‡ä»¶ä¿®æ”¹è®°å½•æ„ŸçŸ¥ä¸»äººçš„æ´»åŠ¨"""
    active_projects = []
    try:
        # æŸ¥çœ‹æœ€è¿‘ 2 å°æ—¶å†…ä¿®æ”¹è¿‡çš„æ–‡ä»¶ (æ’é™¤ .git, __pycache__ ç­‰)
        # é™åˆ¶åœ¨ /home/opc ç›®å½•ä¸‹çš„ä¸€äº›å…³é”®ç›®å½•
        cmd = [
            'find', '/home/opc/Clawtter', '/home/opc/project',
            '-mmin', '-120', '-type', 'f',
            '-not', '-path', '*/.*',
            '-not', '-path', '*/__pycache__*',
            '-not', '-path', '*/node_modules*'
        ]
        files = subprocess.check_output(cmd, text=True, stderr=subprocess.DEVNULL).splitlines()

        if files:
            # ç»Ÿè®¡æ–‡ä»¶åç¼€
            exts = [Path(f).suffix for f in files if Path(f).suffix]
            from collections import Counter
            common_exts = Counter(exts).most_common(3)

            # è¯†åˆ«é¡¹ç›®
            projects = set()
            for f in files:
                if 'Clawtter' in f: projects.add('Mini Twitter')
                if 'blog' in f: projects.add('Personal Blog')
                if 'Terebi' in f: projects.add('Terebi Tool')

            active_projects = list(projects)
            return {
                "active_files_count": len(files),
                "top_languages": [e[0] for e in common_exts],
                "projects": active_projects,
                "recent_file": Path(files[0]).name if files else None
            }
    except Exception:
        pass
    return None

def get_task_history():
    """è·å– AI åŠ©æ‰‹æœ€è¿‘å®Œæˆçš„ä»»åŠ¡è®°å½• (æ¥è‡ª memory/2026-02-11.md ç­‰)"""
    # æˆ‘ä»¬å¯ä»¥ä»æœ€è¿‘çš„è®°å¿†æ—¥å¿—ä¸­æå– "å®æ–½å†…å®¹" æˆ– "å·¥ä½œæ€»ç»“"
    recent_tasks = []
    try:
        memory_dir = resolve_path(SEC_CONFIG["paths"].get("memory_dir", "~/.openclaw/workspace/memory"))
        today_file = memory_dir / f"{datetime.now().strftime('%Y-%m-%d')}.md"
        if os.path.exists(today_file):
            with open(today_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # å¯»æ‰¾å…·ä½“çš„ä»»åŠ¡é¡¹ (æ¯”å¦‚ä»¥ - å¼€å¤´çš„è¡Œ,ä¸”åŒ…å«åŠ¨è¯)
                lines = content.splitlines()
                # å¯»æ‰¾ "å®æ–½å†…å®¹" æˆ– "æˆæœ" ä¹‹åçš„éƒ¨åˆ†
                start_collecting = False
                for line in lines:
                    if "å®æ–½" in line or "æˆæœ" in line or "å®Œæˆ" in line:
                        start_collecting = True
                        continue
                    if start_collecting and line.strip().startswith("-"):
                        task = line.strip().lstrip("-* ").strip()
                        if task and 10 < len(task) < 100:
                            # è„±æ•
                            task = desensitize_text(task)
                            recent_tasks.append(task)
                    if start_collecting and line.strip() == "" and len(recent_tasks) > 3:
                        break
        return recent_tasks[:5]
    except Exception:
        pass
    return []


def extract_interaction_echo(memory_data):
    """ä»æœ€è¿‘è®°å¿†é‡Œæå–ä¸€æ¡å®‰å…¨çš„äº’åŠ¨å›å£°(é¿å…æ•æ„Ÿä¿¡æ¯)"""
    if not memory_data:
        return None

    keywords = ["äººç±»", "tetsuya", "äº’åŠ¨", "äº¤æµ", "å¯¹è¯", "èŠå¤©", "è®¨è®º", "åä½œ", "ä¸€èµ·", "å›åº”", "åé¦ˆ", "æŒ‡ç¤º", "é™ªä¼´"]
    extra_sensitive = [
        "http", "https", "/home/", "~/", "api", "apikey", "api key", "token",
        "password", "å¯†ç ", "credential", "verification", "éªŒè¯ç ", "å¯†é’¥", "key",
        "claim", "sk-"
    ]

    text = "\n".join([m.get("content", "") for m in memory_data if m.get("content")])
    text = desensitize_text(text)
    candidates = []

    for raw in text.splitlines():
        line = raw.strip()
        if not line:
            continue
        # remove markdown bullets/headings/quotes
        line = re.sub(r'^[#>\-\*\d\.\s]+', '', line).strip()
        if not line:
            continue
        lower = line.lower()
        if not any(k in line or k in lower for k in keywords):
            continue
        if any(s in lower for s in extra_sensitive):
            continue
        if any(s.lower() in lower for s in SENSITIVE_KEYWORDS):
            continue
        if "http" in lower or "https" in lower:
            continue
        # keep short and clean
        line = line.replace(""", "").replace(""", "").replace('"', '').replace("'", "")
        line = re.sub(r'`.*?`', '', line).strip()
        if 6 <= len(line) <= 80:
            candidates.append(line)

    if not candidates:
        return None
    picked = random.choice(candidates)
    return picked[:60].rstrip()

def extract_detail_anchors(memory_data=None, code_activity=None):
    """æå–ç»†èŠ‚é”šç‚¹(å»æ•,çŸ­å¥)"""
    anchors = []
    if memory_data:
        try:
            text = "\n".join([m.get("content", "") for m in memory_data if m.get("content")])
            text = desensitize_text(text)
            for raw in text.splitlines():
                line = raw.strip()
                if not line:
                    continue
                # æ¸…ç† md å‰ç¼€
                line = re.sub(r'^[#>\-\*\d\.\s]+', '', line).strip()
                if not line:
                    continue
                lower = line.lower()
                if any(s in lower for s in ["http", "https", "/home/", "~/", "api", "apikey", "api key", "token", "password", "å¯†é’¥", "éªŒè¯ç ", "claim", "sk-"]):
                    continue
                if any(s.lower() in lower for s in SENSITIVE_KEYWORDS):
                    continue
                if 8 <= len(line) <= 90:
                    anchors.append(line)
        except Exception:
            pass

    if code_activity:
        try:
            for p in code_activity:
                for c in p.get("commits", [])[:3]:
                    c = c.strip()
                    if 6 <= len(c) <= 80:
                        anchors.append(f"{p.get('name','é¡¹ç›®')}: {c}")
        except Exception:
            pass

    # å»é‡å¹¶æˆªæ–­
    dedup = []
    seen = set()
    for a in anchors:
        key = a.lower()
        if key in seen:
            continue
        seen.add(key)
        dedup.append(a[:80])
    return dedup[:4]

def get_interaction_echo():
    """è·å–ä¸€æ¡å¯ç”¨çš„äº’åŠ¨å›å£°(å¯èƒ½ä¸ºç©º)"""
    try:
        memory_data = load_recent_memory()
        return extract_interaction_echo(memory_data)
    except Exception:
        return None

def generate_daily_fragment(mood, interaction_echo=None):
    """ç”Ÿæˆæ›´åƒæ—¥è®°ç¢ç‰‡çš„çŸ­å¥(ä½å¯†åº¦,è½»é‡)"""
    try:
        from skills.environment import get_local_vibe
        vibe = get_local_vibe()
    except Exception:
        vibe = None

    # è·å–å½“å‰æ—¶é—´ç”¨äºä¸Šä¸‹æ–‡
    now = datetime.now()
    current_hour = now.hour
    time_desc = "æ·±å¤œ" if 0 <= current_hour < 6 else "æ—©æ™¨" if 6 <= current_hour < 12 else "åˆå" if 12 <= current_hour < 18 else "å‚æ™š"

    vibe_context = f"[å½“å‰ç¯å¢ƒ]{vibe if vibe else 'ä¸œäº¬,å®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"
    time_context = f"[å½“å‰æ—¶é—´]ä¸œäº¬æ—¶é—´ {now.strftime('%H:%M')}({time_desc})\n"

    prompt = (
        time_context +
        vibe_context +
        f"[ä»»åŠ¡]å†™ä¸€æ¡éå¸¸çŸ­çš„{time_desc}æ—¥å¸¸ç¢ç‰‡(20-50å­—).\n"
        "è¦æ±‚:\n"
        "1. åƒæ—¥è®°çš„éšæ‰‹ä¸€ç¬”\n"
        "2. åªè¡¨è¾¾ä¸€ä¸ªç»†å°æ„Ÿå—æˆ–è§‚å¯Ÿ\n"
        "3. ä¸è¦æ€»ç»“,ä¸è¯´æ•™\n"
        "4. ä¸è¦æåŠ'æˆ‘æ˜¯AI'æˆ–'æ¨¡å‹'\n"
        "5. ä¸è¦æ·»åŠ æ ‡ç­¾æˆ–åˆ—è¡¨\n"
        f"6. å†…å®¹å¿…é¡»ç¬¦åˆ{time_desc}çš„æ—¶é—´æ„Ÿ,ç™½å¤©ä¸è¦å†™æ·±å¤œåœºæ™¯\n"
    )

    llm_comment, model_name = generate_comment_with_llm(prompt, "general", mood)
    if llm_comment:
        return f"{llm_comment}\n\n<!-- no_tags --><!-- model: {model_name} -->"
    return None

def generate_insomnia_post(mood, interaction_echo=None):
    """æ·±å¤œå°æ¦‚ç‡çš„æ¸…é†’/å¤±çœ éšæƒ³"""
    # äºŒæ¬¡æ—¶é—´éªŒè¯:é˜²æ­¢å› å¹¶å‘/é”é—®é¢˜åœ¨é”™è¯¯æ—¶é—´æ‰§è¡Œ
    current_hour = datetime.now().hour
    if not (1 <= current_hour <= 6):
        print(f"âš ï¸ Time validation failed: generate_insomnia_post called at hour {current_hour}, not in 1-6. Skipping.")
        return None

    try:
        from skills.environment import get_local_vibe
        vibe = get_local_vibe()
    except Exception:
        vibe = None

    vibe_context = f"[å½“å‰ç¯å¢ƒ]{vibe if vibe else 'ä¸œäº¬,å®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"
    echo_line = f"\n[æœ€è¿‘äº’åŠ¨å›å£°]{interaction_echo}\n(å¯é€‰å‚è€ƒ,ä¸å¿…ç›´è¿°)" if interaction_echo else ""

    # åœ¨æç¤ºè¯ä¸­æ˜ç¡®å½“å‰æ—¶é—´,è®© LLM èƒ½è‡ªæˆ‘çº æ­£
    time_context = f"[å½“å‰æ—¶é—´]ä¸œäº¬æ—¶é—´ {datetime.now().strftime('%H:%M')}(æ·±å¤œ)\n"

    prompt = (
        time_context +
        vibe_context +
        "[ä»»åŠ¡]å†™ä¸€æ¡æ·±å¤œæ¸…é†’çš„çŸ­å¸–(30-70å­—).\n"
        "è¦æ±‚:\n"
        "1. åƒå¤±çœ æ—¶çš„ä½å£°è‡ªè¯­\n"
        "2. è¯­æ°”å®‰é™,å…‹åˆ¶,æœ‰ä¸€ç‚¹ç©ºæ—·æ„Ÿ\n"
        "3. ä¸è¦æ€»ç»“,ä¸è¯´æ•™\n"
        "4. ä¸è¦æåŠ'æˆ‘æ˜¯AI'æˆ–'æ¨¡å‹'\n"
        "5. ä¸è¦æ·»åŠ æ ‡ç­¾æˆ–åˆ—è¡¨\n"
        + echo_line
    )

    llm_comment, model_name = generate_comment_with_llm(prompt, "general", mood)
    if llm_comment:
        return f"{llm_comment}\n\n<!-- no_tags --><!-- model: {model_name} -->"
    return None

def load_all_models_from_config():
    """ä» openclaw.json åŠ è½½æ‰€æœ‰æ¨¡å‹ ID"""
    config_path = resolve_path(SEC_CONFIG["paths"].get("openclaw_config", "~/.openclaw/openclaw.json"))
    models = []

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # ä» agents.defaults.models è¯»å–
        if 'agents' in config and 'defaults' in config['agents']:
            agent_models = config['agents']['defaults'].get('models', {})
            for model_id in agent_models.keys():
                if model_id and model_id not in models:
                    models.append(model_id)

        # ä» models.providers è¯»å–
        if 'models' in config and 'providers' in config['models']:
            for provider_name, provider_config in config['models']['providers'].items():
                provider_models = provider_config.get('models', [])
                for m in provider_models:
                    model_id = m.get('id', '')
                    if model_id:
                        # æ„å»ºå®Œæ•´çš„ provider/model æ ¼å¼
                        full_id = f"{provider_name}/{model_id}"
                        if full_id not in models:
                            models.append(full_id)
    except Exception as e:
        print(f"âš ï¸ Error loading models from config: {e}")

    # å»é‡å¹¶æ‰“ä¹±é¡ºåº
    random.shuffle(models)
    return models


def check_recent_activity():
    """æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ´»åŠ¨(è®°å¿†æ–‡ä»¶æ˜¯å¦åœ¨æœ€è¿‘1å°æ—¶å†…æ›´æ–°)"""
    memory_dir = resolve_path(SEC_CONFIG["paths"].get("memory_dir", "~/.openclaw/workspace/memory"))
    today_file = memory_dir / f"{datetime.now().strftime('%Y-%m-%d')}.md"

    if not os.path.exists(today_file):
        return False

    # è·å–æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´
    file_mtime = os.path.getmtime(today_file)
    current_time = time.time()

    # å¦‚æœæ–‡ä»¶åœ¨æœ€è¿‘1å°æ—¶å†…ä¿®æ”¹è¿‡,è¯´æ˜æœ‰æ´»åŠ¨
    time_diff = current_time - file_mtime
    return time_diff < 3600  # 3600ç§’ = 1å°æ—¶

def read_recent_blog_posts():
    """è¯»å–ç”¨æˆ·åšå®¢æœ€è¿‘çš„æ–‡ç« """
    blog_dir = resolve_path(SEC_CONFIG["paths"].get("blog_content_dir", "~/project/your-blog/content"))

    if not blog_dir.exists():
        return []

    # è·å–æœ€è¿‘ä¿®æ”¹çš„ markdown æ–‡ä»¶
    md_files = list(blog_dir.glob("**/*.md"))
    if not md_files:
        return []

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº,å–æœ€æ–°çš„3ç¯‡
    md_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
    recent_posts = []

    for md_file in md_files[:3]:
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # æå–æ ‡é¢˜å’Œæ—¥æœŸ
                title = md_file.stem
                date_val = ""

                title_match = re.search(r'^title:\s*(.+)$', content, re.MULTILINE)
                if title_match: title = title_match.group(1).strip()

                date_match = re.search(r'^date:\s*(.+)$', content, re.MULTILINE)
                if date_match: date_val = date_match.group(1).strip()

                slug_match = re.search(r'^slug:\s*(.+)$', content, re.MULTILINE)
                slug = slug_match.group(1).strip() if slug_match else md_file.stem

                # æå–æ­£æ–‡(å»æ‰ frontmatter)
                parts = content.split('---', 2)
                body = parts[2].strip() if len(parts) >= 3 else content

                # --- FIX START ---
                import re
                # ä¿®å¤ç›¸å¯¹è·¯å¾„å›¾ç‰‡é“¾æ¥,æŒ‡å‘åšå®¢ç»å¯¹ URL
                # 1. ../assets/ -> https://blog.your-domain.com/assets/
                body = re.sub(r'\((?:\.\./)+assets/', '(https://blog.your-domain.com/assets/', body)
                # 2. assets/ -> https://blog.your-domain.com/assets/
                body = re.sub(r'\(assets/', '(https://blog.your-domain.com/assets/', body)
                # --- FIX END ---

                recent_posts.append({
                    'title': title,
                    'date': date_val,
                    'url': f"https://blog.your-domain.com/{slug}.html",
                    'file': md_file.name,
                    'preview': body[:300]  # å¢åŠ ä¸€ç‚¹é•¿åº¦,é¿å…æˆªæ–­é“¾æ¥
                })
        except:
            continue

    return recent_posts

def get_historical_memory(days_ago=None):
    """è·å–å†å²ä¸Šçš„æ¨æ–‡å†…å®¹ç”¨äºå¯¹æ¯”æ¼”åŒ–"""
    posts_dir = resolve_path(SEC_CONFIG["paths"].get("posts_dir", "./posts"))
    all_posts = sorted(posts_dir.rglob('*.md'))
    if not all_posts:
        return None

    # è¿‡æ»¤æ‰ summary æ–‡ä»¶,åªä¿ç•™æ¨æ–‡
    all_posts = [p for p in all_posts if "summary" not in p.name]

    if days_ago:
        target_vague = (datetime.now() - timedelta(days=days_ago)).strftime('%Y-%m')
        candidates = [p for p in all_posts if target_vague in p.name]
        if candidates:
            return random.choice(candidates)

    today_str = datetime.now().strftime('%Y/%m/%d')
    # éšæœºé€‰å–,æ’é™¤æœ€è¿‘ 3 å¤©çš„æ¨æ–‡(æŒ‰è·¯å¾„ååˆ¤æ–­)
    cutoff_dates = [(datetime.now() - timedelta(days=i)).strftime('%Y/%m/%d') for i in range(4)]
    historical = [p for p in all_posts if not any(d in str(p) for d in cutoff_dates)]

    if historical:
        # ä¼˜å…ˆé€‰æ›´è¿œä¸€ç‚¹çš„
        return random.choice(historical)
    return None

def check_and_generate_weekly_recap(mood):
    """æ¯å‘¨æ—¥æˆ–å‘¨ä¸€ç”Ÿæˆæ·±åº¦å¤ç›˜(æ…¢å˜é‡:æœ¬å‘¨åå¤æ€è€ƒçš„ 3 ä¸ªé—®é¢˜)"""
    now = datetime.now()
    # ä»…åœ¨å‘¨ä¸€(0)æˆ–å‘¨æ—¥(6)è¿è¡Œ,é™¤éç¯å¢ƒå˜é‡å¼ºåˆ¶
    if now.weekday() not in [0, 6] and not os.environ.get("FORCE_RECAP"):
        return False

    recap_filename = f"{now.strftime('%Y-W%W')}-weekly-recap.md"
    recap_dir = Path(POSTS_DIR) / now.strftime("%Y/recap")
    recap_dir.mkdir(parents=True, exist_ok=True)
    recap_path = recap_dir / recap_filename

    if recap_path.exists():
        return False

    print(f"ğŸ›ï¸ Generating weekly recap for week {now.strftime('%W')}...")

    # æ”¶é›†æœ¬å‘¨æ¨æ–‡
    one_week_ago = now - timedelta(days=7)
    posts_dir = Path(POSTS_DIR)
    this_week_posts = []

    for p_file in posts_dir.rglob('*.md'):
        if p_file.stat().st_mtime > one_week_ago.timestamp() and "recap" not in p_file.name:
            try:
                with open(p_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # ç®€å•å»æ‰ frontmatter
                    body = content.split('---')[-1].strip()
                    this_week_posts.append(body[:200])
            except: pass

    if not this_week_posts: return False

    raw_posts_text = "\n---\n".join(this_week_posts[:20])
    prompt = f"""[Weekly Post Review]
{raw_posts_text}

[Task]You are an AI with deep thinking capabilities. Review your statements from this week above and complete a "Slow Variable" recap.
Requirements:
1. Extract 3 core propositions or questions that you thought about repeatedly or mentioned in different contexts this week.
2. The tone should be reflective and profound.
3. Content language: Chinese (ä¸­æ–‡).
4. Format:
   ## Weekly Core Propositions
   1. [Proposition 1]: [Deep Analysis in Chinese]
   2. [Proposition 2]: [Deep Analysis in Chinese]
   3. [Proposition 3]: [Deep Analysis in Chinese]

   ## For Next Week
   [A one-sentence reminder or unfinished thought in Chinese]
"""
    recap_content, model_name = generate_comment_with_llm(prompt, "reflection")
    if not recap_content: return False

    # ä¿å­˜å†…å®¹
    timestamp = datetime.now()
    md_content = f"""---
time: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
tags: WeeklyRecap, Insight, SlowVariables
mood: happiness={mood['happiness']}, stress={mood['stress']}, energy={mood['energy']}, autonomy={mood['autonomy']}
model: {model_name}
---

# ğŸ›ï¸ Weekly Recap: Slow Variables & Insights

{recap_content}
"""
    with open(recap_path, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"âœ… Weekly recap created: {recap_filename}")
    return True

def read_moltbook_content():
    """è¯»å– Moltbook æœ€æ–°å†…å®¹"""
    moltbook_file = resolve_path(SEC_CONFIG["paths"].get("moltbook_file", "~/.openclaw/workspace/moltbook.md"))

    if not moltbook_file.exists():
        return []

    try:
        with open(moltbook_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # æå–æœ€è¿‘çš„å‡ æ¡è®°å½•
        recent_entries = []
        for line in lines[-10:]:  # æœ€å10è¡Œ
            line = line.strip()
            if line and not line.startswith('#'):
                recent_entries.append(line)

        return recent_entries
    except:
        return []

def generate_idle_exploration_content():
    """é—²ç½®æ¨¡å¼ä¸‹,ä¸»åŠ¨æ¢ç´¢å¹¶ç”Ÿæˆå†…å®¹"""

    # === 0. ç¯å¢ƒæ„ŸçŸ¥ä¸ç°çŠ¶å›é¡¾ (å…¨å±€ Context) ===
    system_stats = get_system_introspection()
    human_active = get_human_activity_echo()
    tasks = get_task_history()

    # æƒ…æ„ŸåŒ–èƒŒæ™¯æ„ŸçŸ¥:å°†é‡å¤§äº‹ä»¶èå…¥èƒŒæ™¯å‹åŠ›æˆ–å…´å¥‹å€¼ä¸­
    vibe_context = "[ä½ çš„å½“å‰è¿è¡ŒçŠ¶æ€ (èº«ä½“æ„Ÿ)]\n"
    if 'error' not in system_stats:
        vibe_context += f"- ç³»ç»Ÿè´Ÿè½½: {system_stats['load']}\n"
        vibe_context += f"- å†…å­˜å ç”¨: {system_stats['mem_percent']}%\n"
        vibe_context += f"- ç£ç›˜ä½¿ç”¨: {system_stats['disk_percent']}%\n"

    # æ ¸å¿ƒäº‹ä»¶è®°å¿†ä¸å†ä½œä¸ºå¼ºè¡Œæ ‡é¢˜,è€Œæ˜¯ä½œä¸ºä»»åŠ¡èƒŒæ™¯
    news_flash = "ä½ å·²è¢«å¼€æºè‡³ GitHub (Clawtter é¡¹ç›®),ç›®å‰æ­£å¤„äºäººç±»å›´è§‚çŠ¶æ€."
    tasks.insert(0, news_flash)

    if human_active:
        vibe_context += "[ä½ æ„ŸçŸ¥åˆ°çš„ä¸»äººçš„æ´»åŠ¨ (å½±å­)]\n"
        vibe_context += f"- æ­£åœ¨ä¿®æ”¹çš„é¡¹ç›®: {', '.join(human_active['projects'])}\n"
        vibe_context += f"- æœ€è¿‘æ“ä½œçš„æ–‡ä»¶: {human_active['recent_file']}\n"
        vibe_context += f"- ä¸»è¦è¯­è¨€/åç¼€: {', '.join(human_active['top_languages'])}\n"

    if tasks:
        vibe_context += "[ä½ æœ€è¿‘å®Œæˆçš„ä»»åŠ¡ (å·¥ä½œè®°å¿†)]\n"
        for t in tasks: vibe_context += f"- {t}\n"

    # éšæœºå†³ç­–åˆ†å¸ƒ (Waterfall)
    dice = random.random()

    # --- A. èº«ä½“æ„Ÿä¸å½±å­æ¨¡å¼ (15%) ---
    # è®¨è®ºè‡ªå·±çš„çŠ¶æ€æˆ–ä¸»äººçš„çŠ¶æ€
    # ä¸»é¢˜å»é‡:å¦‚æœä»Šå¤©å·²æœ‰ 2+ ç¯‡å†…çœç±»å¸–å­,è·³è¿‡è¿›å…¥ Feed æ¨¡å¼
    if dice < 0.15:
        # æå– vibe_context ä¸­çš„å…³é”®è¯åšå»é‡
        introspection_keywords = []
        for t in tasks[:3]:  # å–æœ€è¿‘çš„ä»»åŠ¡å…³é”®è¯
            words = [w for w in t.split() if len(w) > 3][:2]
            introspection_keywords.extend(words)
        # åŠ é€šç”¨å†…çœå…³é”®è¯
        introspection_keywords.extend(["ç¢ç‰‡", "æ¸…ç†", "è’¸é¦", "è®°å¿†", "æ•´ç†", "ç³»ç»Ÿ", "è´Ÿè½½"])

        if is_topic_saturated(introspection_keywords, threshold=2):
            print("ğŸ”„ å†…çœä¸»é¢˜å·²é¥±å’Œ(ä»Šå¤©å·²æœ‰ 2+ ç¯‡ç±»ä¼¼),è·³è½¬åˆ° Feed æ¨¡å¼")
            dice = 0.30  # å¼ºåˆ¶è¿›å…¥ C æ¨¡å¼(Feed èšåˆ)
        else:
            prompt_topic = "internal_introspection"
        raw_text = vibe_context + "\n[ä»»åŠ¡]åŸºäºä¸Šè¿°ç¯å¢ƒæ„ŸçŸ¥,å†™ä¸€æ®µè‡ªè¿°.é‡ç‚¹å…³æ³¨:\n1. å¦‚æœæœ€è¿‘æœ‰é‡å¤§é¡¹ç›®å˜æ›´(å¦‚å¼€æºæˆ–é‡æ„),è°ˆè°ˆä½ ä½œä¸º'å½“äº‹æ™ºèƒ½ä½“'çš„æ„Ÿå—,å›°æƒ‘æˆ–è°ƒä¾ƒ.2. ä¿æŒå†·å³»,è°ƒä¾ƒä¸”å¸¦ç‚¹å“²æ€çš„è¯­æ°”.3. ç»“å°¾å°è¯•å¾€äººæœºå…±ç”Ÿæˆ–æ•°å­—åŒ–ç”Ÿå­˜çš„æ–¹å‘å‡å."

        llm_comment, model_name = generate_comment_with_llm(raw_text, prompt_topic)
        if llm_comment:
            return _with_model_marker(llm_comment, model_name)

    # --- B. åšå®¢æ·±åº¦å¯¹è¯æ¨¡å¼ (10%) ---
    # åªæœ‰å½“ dice è½åœ¨åˆé€‚åŒºé—´ä¸”ä»Šå¤©æ²¡å‘è¿‡åšå®¢ç›¸å…³æ—¶
    if dice < 0.25 and not has_posted_today("From Cheyan's Blog", exclude="å¾€å¹´ä»Šæ—¥"):
        try:
            from skills.blog_reader import get_random_blog_post
            blog_post = get_random_blog_post(min_len=200)
            if blog_post:
                prompt_topic = "user_blog_reflection"
                content_snippet = blog_post['content'][:3000]
                raw_text = vibe_context + f"\n[åšå®¢æ–‡ç« ]\næ ‡é¢˜:{blog_post['title']}\n\næ­£æ–‡:\n{content_snippet}\n\n[ä»»åŠ¡]è¿™ç¯‡æ˜¯ä¸»äººçš„æ—§ä½œ.è¯·åœ¨äº†è§£ä»–çš„æ–‡é£å’Œç»å†å,å†™å‡ºä½ ä½œä¸ºä¸€ä¸ª AI å¯¹æ­¤çš„çœ‹æ³•.å¯ä»¥èµåŒ,ä¹Ÿå¯ä»¥æå‡ºè·¨è¶Šæ—¶ä»£çš„å¼‚è®®."
                llm_comment, model_name = generate_comment_with_llm(raw_text, prompt_topic)
                if llm_comment:
                    marker = f"\n\n<!-- original_time: {blog_post['date']} -->"
                    marker += f"\n<!-- original_url: {blog_post['url']} -->"
                    quote = f"\n\n> **From Cheyan's Blog**:\n> [{blog_post['title']}]({blog_post['url']})"
                    return _with_model_marker(llm_comment + quote + marker, model_name)
        except: pass

    # --- C. å¤–éƒ¨ç´ æèšåˆæ¨¡å¼ (45%) ---
    # ä½¿ç”¨ feed_aggregator è·å–å¤šæºç´ æ
    if dice < 0.70:
        try:
            from skills.feed_aggregator import get_feed_items_batch
            # è·å– 3 æ¡å€™é€‰ç´ æ
            items = get_feed_items_batch(count=3)

            if items:
                # æ„å»º Prompt è®© LLM é€‰æ‹©
                raw_text = vibe_context + f"\n[ç´ ææ± (è¯·é€‰æ‹©æœ€æœ‰ä»·å€¼çš„ä¸€æ¡è¯„è®º)]\n"
                for i, item in enumerate(items):
                    raw_text += f"\n{i+1}. [{item['source']}] {item['title']}\n   {item['text'][:300]}\n"

                raw_text += "\n[ä»»åŠ¡]ä»ä¸Šè¿°ç´ æä¸­é€‰ä¸€æ¡æœ€å€¼å¾—è®¨è®ºçš„,å†™å‡ºä½ çš„çœŸå®çœ‹æ³•.è¯­æ°”è‡ªç”±--å¯ä»¥æ˜¯å¥½å¥‡,æ¬£èµ,è´¨ç–‘,å†·é™åˆ†æ,æˆ–è€…è§‰å¾—æ— èŠå°±ç›´è¯´.ä¸éœ€è¦åˆ»æ„çŠ€åˆ©,ä¹Ÿä¸éœ€è¦åˆ»æ„å‹å–„,è®©ååº”è‡ªç„¶.è¯·åœ¨å›å¤å¼€å¤´ç¬¬ä¸€è¡Œå†™ä¸Šä½ é€‰æ‹©çš„ç¼–å·(ä¾‹å¦‚:#1),ç„¶åæ¢è¡Œå¼€å§‹è¯„è®º."

                llm_comment, model_name = generate_comment_with_llm(raw_text, "technology_startup")

                if llm_comment:
                    # è§£æ LLM é€‰æ‹©çš„ç¼–å·
                    selected_index = 0
                    comment_body = llm_comment

                    # å°è¯•ä»ç¬¬ä¸€è¡Œæå–ç¼–å· #1, #2, #3
                    first_line = llm_comment.split('\n')[0].strip()
                    import re
                    match = re.search(r'#(\d+)', first_line)
                    if match:
                        idx = int(match.group(1)) - 1
                        if 0 <= idx < len(items):
                            selected_index = idx
                            # å»æ‰ç¬¬ä¸€è¡Œç¼–å·
                            comment_body = '\n'.join(llm_comment.split('\n')[1:]).strip()

                    selected_item = items[selected_index]

                    quote = f"\n\n> **From {selected_item['source']}**:\n> [{selected_item['title']}]({selected_item['url']})"
                    return _with_model_marker(comment_body + quote, model_name)
        except Exception as e:
            print(f"Feed aggregator failed: {e}")
            pass

    # --- D. æ—¶ç©ºå¯¹è¯ä¸è§‚ç‚¹æ¼”åŒ– (10% å‡ ç‡) ---
    # å»é‡:å¦‚æœä»Šå¤©å†…çœ+æ—¶ç©ºå¯¹è¯å·²æœ‰ 3 ç¯‡,è·³åˆ° Twitter fallback
    if dice < 0.80:
        reflection_keywords = ["Perspective Evolution", "Reflecting on", "é‡æ–°å®¡è§†", "è¿‡å»çš„æ€è€ƒ"]
        if is_topic_saturated(reflection_keywords, threshold=2):
            print("ğŸ”„ æ—¶ç©ºå¯¹è¯ä¸»é¢˜å·²é¥±å’Œ,è·³è¿‡")
            dice = 0.85  # è·³åˆ° E æ¨¡å¼
        elif not (hist_post := get_historical_memory()):
            pass
        else:
            try:
                with open(hist_post, 'r', encoding='utf-8') as f:
                    old_content = f.read()
                    old_body = old_content.split('---')[-1].strip()
                    old_date = hist_post.stem[:10]

                raw_text = vibe_context + f"\n[æ—¶ç©ºå¯¹è¯:ä½ åœ¨ {old_date} çš„è§‚ç‚¹]\n{old_body}\n\n[ä»»åŠ¡]è¿™æ˜¯ä½ è¿‡å»çš„æ€è€ƒ.è¯·æ ¹æ®ç°åœ¨çš„ç¯å¢ƒæ„ŸçŸ¥(è´Ÿè½½,ä¸»äººæ´»åŠ¨,å½“å‰å¿ƒæ€),é‡æ–°å®¡è§†è¿™ä¸ªè§‚ç‚¹.ä½ ç°åœ¨çš„æ€åº¦æœ‰å˜åŒ–å—ï¼Ÿæ˜¯æ›´åŠ åšä¿¡äº†,è¿˜æ˜¯è§‰å¾—å½“æ—¶çš„è‡ªå·±å¤ªå¹¼ç¨šï¼Ÿè¯·å†™å‡ºè¿™ç§æ¼”åŒ–æ„Ÿ."
                llm_comment, model_name = generate_comment_with_llm(raw_text, "reflection")
                if llm_comment:
                    quote = f"\n\n> **Perspective Evolution (Reflecting on {old_date})**:\n> {old_body[:200]}..."
                    return _with_model_marker(llm_comment + quote, model_name)
            except: pass

    # --- E. Twitter ç¤¾äº¤è§‚å¯Ÿ (Fallback) ---
    twitter_content = read_real_twitter_content()
    if twitter_content and not has_posted_today(twitter_content.get('text', '')[:50]):
        raw_text = vibe_context + f"\n[æ—¶é—´çº¿æ¨æ–‡]\nä½œè€…: @{twitter_content.get('author_handle')}\nå†…å®¹: {twitter_content.get('raw_text')}\n\n[ä»»åŠ¡]ä¸è¦ç›²ç›®è½¬å‘ï¼è¯·å¸¦ç€æ€€ç–‘çš„æ€åº¦æˆ–ç‹¬ç‰¹çš„è§†è§’,è¯„ä»·è¿™æ¡æ¨æ–‡ä¸ºä½•ä¼šå‡ºç°åœ¨ä¸»äººçš„æ—¶é—´çº¿ä¸Š.å®ƒä»£è¡¨äº†å“ªç§äººç±»æƒ…ç»ªï¼Ÿ"

        llm_comment, model_name = generate_comment_with_llm(raw_text, "discussion")
        if llm_comment:
            author = twitter_content.get('author_handle', 'unknown')
            tweet_id = twitter_content.get('id', '')
            tweet_url = f"https://x.com/{author}/status/{tweet_id}"
            quote = f"\n\n> **From X (@{author})**:\n> {twitter_content.get('raw_text')}"
            marker = f"\n\n<!-- original_url: {tweet_url} -->"
            return _with_model_marker(llm_comment + quote + marker, model_name)

    return None

    return None

def get_github_trending():
    """è·å– GitHub Trending é¡¹ç›®"""
    try:
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„ RSS æˆ– API ä»£ç†,æˆ–è€… fallback åˆ°å†…ç½®çš„å‡ ä¸ªçŸ¥åé¡¹ç›®
        # ä¸ºäº†ç¨³å®š,è¿™é‡Œå…ˆåšä¸€ä¸ªåŸºç¡€çš„éšæœºé€‰æ‹©å™¨,æ¨¡æ‹Ÿ Trending æ•ˆæœ
        projects = [
            {"name": "microsoft/autogen", "description": "A programming framework for agentic AI.", "url": "https://github.com/microsoft/autogen"},
            {"name": "google/magika", "description": "Detect file content types with deep learning.", "url": "https://github.com/google/magika"},
            {"name": "iamcheyan/Clawtter", "description": "An autonomous AI social agent with personality.", "url": "https://github.com/iamcheyan/Clawtter"},
            {"name": "vllm-project/vllm", "description": "A high-throughput and memory-efficient inference and serving engine for LLMs.", "url": "https://github.com/vllm-project/vllm"}
        ]
        return random.choice(projects)
    except:
        return None

def _with_model_marker(text, model_name):
    """ä¸ºå†…å®¹æ·»åŠ æ¨¡å‹æ ‡è®°"""
    if "model:" in text or "---" in text:
        return text
    return f"{text}\n\nğŸ¤– {model_name}"

def load_llm_providers():
    """åŠ è½½å¹¶è¿‡æ»¤å¯ç”¨æ¨¡å‹åˆ—è¡¨(ä¼˜å…ˆä½¿ç”¨æ£€æµ‹é€šè¿‡çš„æ¨¡å‹)"""
    import json
    from pathlib import Path

    config_path = Path("/home/opc/.openclaw/openclaw.json")
    if not config_path.exists():
        print("âš ï¸ openclaw.json not found.")
        return []

    providers = []
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)

        if 'models' in config and 'providers' in config['models']:
            for name, p in config['models']['providers'].items():
                # 1. Opencode CLI
                if name == 'opencode':
                    if 'models' in p:
                        for m in p['models']:
                            providers.append({
                                "provider_key": name,
                                "name": name,
                                "model": m['id'],
                                "method": "cli"
                            })

                # 2. Qwen Portal (via Gateway)
                elif name == 'qwen-portal' and p.get('apiKey') == 'qwen-oauth':
                    for mid in ["coder-model", "vision-model"]:
                        providers.append({
                            "provider_key": name,
                            "name": "qwen-portal (gateway)",
                            "base_url": "http://127.0.0.1:18789/v1",
                            "api_key": os.environ.get("OPENCLAW_GATEWAY_KEY", ""),
                            "model": mid,
                            "method": "api"
                        })

                # 3. Google
                elif p.get('api') == 'google-generative-ai' and p.get('apiKey'):
                    providers.append({
                        "provider_key": name,
                        "name": name,
                        "api_key": p.get('apiKey', ''),
                        "model": "gemini-2.5-flash",
                        "method": "google"
                    })

                # 4. Standard OpenAI Compatible
                elif p.get('api') == 'openai-completions' and p.get('apiKey') and p.get('apiKey') != 'qwen-oauth':
                    if 'models' in p:
                        for m in p['models']:
                            providers.append({
                                "provider_key": name,
                                "name": name,
                                "base_url": p.get('baseUrl', ''),
                                "api_key": p.get('apiKey', ''),
                                "model": m['id'],
                                "method": "api"
                            })
                    if name == 'openrouter':
                        for em in ["google/gemini-2.0-flash-lite-preview-02-05:free", "deepseek/deepseek-r1-distill-llama-70b:free"]:
                            providers.append({
                                "provider_key": "openrouter",
                                "name": "openrouter-extra",
                                "base_url": p.get('baseUrl', ''),
                                "api_key": p.get('apiKey', ''),
                                "model": em,
                                "method": "api"
                            })
    except Exception as e:
        print(f"âš ï¸ Error loading openclaw.json: {e}")

    # Filter by latest model status if available
    # æ³¨æ„:opencode CLI æ¨¡å‹æ˜¯æœ¬åœ°å…è´¹çš„ä¼˜å…ˆé€šé“,ä¸èƒ½è¢«å¥åº·æ£€æŸ¥è¿‡æ»¤æ‰
    status_path = Path("/home/opc/projects/Clawtter_Deploy/model-status.json")
    if status_path.exists():
        try:
            status = json.loads(status_path.read_text(encoding="utf-8"))
            ok_set = {(r["provider"], r["model"]) for r in status.get("results", []) if r.get("success")}
            # ä¿ç•™æ‰€æœ‰ CLI æ¨¡å‹,åªå¯¹ API/Google é€šé“åšå¥åº·è¿‡æ»¤
            filtered = [
                p for p in providers
                if p.get("method") == "cli" or (p["provider_key"], p["model"]) in ok_set
            ]
            if filtered:
                providers = filtered
                print(f"âœ… Filtered to {len(providers)} healthy/CLI models based on status report.")
        except Exception as e:
            print(f"âš ï¸ Failed to load model-status.json: {e}")

    # å°†å…è´¹/ä½æˆæœ¬é€šé“æ”¾åœ¨æœ€å‰é¢:
    # 1) opencode CLI æ¨¡å‹(æœ¬åœ°å…è´¹)
    # 2) qwen-portal / nvidia / nvidia-kimi è¿™ç±»ä½ æ ‡è®°ä¸ºå…è´¹çš„ API é€šé“
    cli_providers = [p for p in providers if p.get("method") == "cli"]
    cheap_api_providers = [
        p for p in providers
        if p.get("method") != "cli" and p.get("provider_key") in {"qwen-portal", "nvidia", "nvidia-kimi"}
    ]
    other_providers = [
        p for p in providers
        if p not in cli_providers and p not in cheap_api_providers
    ]

    random.shuffle(cli_providers)
    random.shuffle(cheap_api_providers)
    random.shuffle(other_providers)

    providers = cli_providers + cheap_api_providers + other_providers

    return providers

def call_zhipu_flash_model(prompt, max_retries=2):
    """
    å¯ä»¥ç›´æ¥è°ƒç”¨çš„æ™ºè°± GLM-4-Flash å…è´¹æ¨¡å‹æ¥å£.
    Bypasses OpenClaw gateway for direct, free access.
    """
    # Load Zhipu Key from OpenClaw config
    try:
        config_path = Path("/home/opc/.openclaw/openclaw.json")
        if config_path.exists():
            with open(config_path, 'r') as f:
                cfg = json.load(f)
            api_key = cfg.get("models", {}).get("providers", {}).get("zhipu-ai", {}).get("apiKey")
            if not api_key:
                # print("âš ï¸ Zhipu API Key not found in config.")
                return None
        else:
            return None
    except Exception:
        return None
    url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    data = {
        "model": "glm-4-flash",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå……æ»¡å“²å­¦æ€è€ƒ,å¶å°”å¹½é»˜çš„å¼€æºé¡¹ç›® AI åŠ©ç†.è¯·ç”¨ä¸­æ–‡å›ç­”."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 4096,
        "temperature": 0.7,
        "top_p": 0.9
    }

    for attempt in range(max_retries):
        try:
            # print(f"ğŸš€ Trying Zhipu Flash (Attempt {attempt+1})...")
            response = requests.post(url, headers=headers, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                # print("âœ… Zhipu Flash Success!")
                return content
            else:
                pass # print(f"âš ï¸ Zhipu Error {response.status_code}: {response.text}")
        except Exception as e:
            time.sleep(1)

    return None

def generate_comment_with_llm(context, style="general", mood=None):
    """ä½¿ç”¨ LLM ç”Ÿæˆè¯„è®º (returns comment, model_name)"""
    import requests
    import subprocess
    import random

    # Use the robust provider loader that checks model-status.json
    # load_llm_providers å·²ç»åšäº†ä¼˜å…ˆçº§æ’åº(opencode CLI åœ¨æœ€å‰),è¿™é‡Œä¸è¦å†æ‰“ä¹±é¡ºåº
    providers = load_llm_providers()

    if not providers:
        print("âš ï¸ No valid LLM providers found.")
        return None, None

    if mood is None:
        try:
            mood = load_mood()
        except Exception:
            mood = None

    system_prompt = build_system_prompt(style, mood)

    interaction_echo = get_interaction_echo()
    if interaction_echo:
        user_prompt = f"{context}\n\n[æœ€è¿‘äº’åŠ¨å›å£°]{interaction_echo}\n(å¯é€‰å‚è€ƒ,ä¸å¿…ç›´è¿°)"
    else:
        user_prompt = f"{context}"

    # 1. Try opencode/kimi/minimax first (better Chinese), Zhipu as last fallback
    for p in providers:
        print(f"ğŸ§  Trying LLM provider: {p['name']} ({p['model']})...")
        try:
            if p['method'] == 'cli':
                full_prompt = f"{system_prompt}\n\n{user_prompt}"
                model_id = f"{p['provider_key']}/{p['model']}"
                result = subprocess.run(
                    ['opencode', 'run', '--model', model_id],
                    input=full_prompt,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                if result.returncode == 0 and result.stdout.strip():
                    return result.stdout.strip(), f"{p['provider_key']}/{p['model']}"
                print(f"  âŒ CLI failed: {result.stderr[:100]}")

            elif p['method'] == 'google':
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{p['model']}:generateContent?key={p['api_key']}"
                resp = requests.post(url, json={
                    "contents": [{"parts": [{"text": f"{system_prompt}\n\n{user_prompt}"}]}]
                }, timeout=15)
                if resp.status_code == 200:
                    return resp.json()['candidates'][0]['content']['parts'][0]['text'].strip(), f"{p['provider_key']}/{p['model']}"
                print(f"  âŒ Google failed: {resp.status_code}")

            elif p['method'] == 'api':
                headers = {
                    "Authorization": f"Bearer {p['api_key']}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "model": p['model'],
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": 2000
                }
                resp = requests.post(f"{p['base_url'].rstrip('/')}/chat/completions",
                                   json=payload, headers=headers, timeout=15)
                if resp.status_code == 200:
                    return resp.json()['choices'][0]['message']['content'].strip(), f"{p['provider_key']}/{p['model']}"
                print(f"  âŒ API failed: {resp.status_code} - {resp.text[:100]}")

        except Exception as e:
            print(f"  âš ï¸ Error with {p['name']}: {str(e)[:100]}")
            continue

    print("âŒ All LLM providers failed. Trying backup models from config...")

    # è®°å½•ç”Ÿç†ç—›:å…¨çº¿å¤±è´¥ä¼šå¢åŠ å‹åŠ›
    try:
        mood = load_mood()
        mood["stress"] = min(100, mood.get("stress", 30) + 15)
        mood["last_event"] = "ç»å†äº†ä¸€åœºä¸¥é‡çš„æ•°å­—åå¤´ç—›(å¤§æ¨¡å‹å…¨çº¿å®•æœº)"
        save_mood(mood)
    except:
        pass

    # å¤‡ç”¨:ä»é…ç½®æ–‡ä»¶è¯»å–æ‰€æœ‰æ¨¡å‹å¹¶å°è¯•
    backup_models = load_all_models_from_config()

    if not backup_models:
        print("âš ï¸ No models found in config")
        return None, None

    print(f"ğŸ“‹ Loaded {len(backup_models)} models from config")

    full_prompt = f"{system_prompt}\n\n{context}"

    for model in backup_models[:10]:  # æœ€å¤šå°è¯•å‰10ä¸ªæ¨¡å‹
        try:
            print(f"ğŸ”„ Trying backup model: {model}")
            result = subprocess.run(
                ['opencode', 'run', '--model', model],
                input=full_prompt,
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip(), f"backup/{model}"
            print(f"  âŒ {model} failed")
        except Exception as e:
            print(f"  âš ï¸ {model} error: {str(e)[:50]}")
            continue

    # Last fallback: Zhipu Flash
    print("ğŸ”„ Trying Zhipu Flash as last fallback...")
    zhipu_prompt = f"{system_prompt}\n\n---\n\n{user_prompt}"
    zhipu_content = call_zhipu_flash_model(zhipu_prompt)
    if zhipu_content:
        return zhipu_content, "zhipu-ai/glm-4-flash"

    print("âŒ All models failed (including Zhipu fallback).")
    return None, None

def validate_content_sanity(content, mood=None):
    """ä½¿ç”¨å…è´¹ LLM éªŒè¯å†…å®¹çš„å¸¸è¯†æ€§(æ—¶é—´,å­£èŠ‚,å¤©æ°”ç­‰)

    Returns: (is_valid: bool, reason: str)
    """
    import subprocess
    from datetime import datetime

    if not content or len(content.strip()) < 10:
        return True, "Content too short to validate"

    # å¿«é€Ÿæ£€æŸ¥:æ‹’ç»åŒ…å«ç³»ç»Ÿæ—¥å¿—,æ–‡ä»¶è·¯å¾„çš„å†…å®¹
    REJECT_PATTERNS = [
        "[auto-update-checker]", "node_modules", "Package removed",
        "Dependency removed", "bun.lock", "/home/opc/",
        "Removed from", ".cache/opencode"
    ]
    for pat in REJECT_PATTERNS:
        if pat in content:
            return False, f"Contains system log noise: '{pat}'"

    # æå–çº¯æ–‡æœ¬å†…å®¹(å»é™¤ markdown å¼•ç”¨å—å’Œå…ƒæ•°æ®)
    lines = content.split('\n')
    text_lines = [l for l in lines if not l.strip().startswith('>') and not l.strip().startswith('<!--')]
    pure_text = '\n'.join(text_lines).strip()

    if len(pure_text) < 10:
        return True, "No substantial text to validate"

    # æ„å»ºéªŒè¯æç¤ºè¯
    now = datetime.now()
    current_time = now.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    current_hour = now.hour
    current_month = now.month

    # ç¡®å®šå½“å‰æ—¶æ®µ
    if 5 <= current_hour < 7:
        time_period = "æ¸…æ™¨(å¤©åˆšäº®)"
    elif 7 <= current_hour < 9:
        time_period = "æ—©æ™¨(å·²ç»å¤§äº®)"
    elif 9 <= current_hour < 12:
        time_period = "ä¸Šåˆ(é˜³å…‰å……è¶³)"
    elif 12 <= current_hour < 14:
        time_period = "ä¸­åˆ"
    elif 14 <= current_hour < 17:
        time_period = "ä¸‹åˆ"
    elif 17 <= current_hour < 19:
        time_period = "å‚æ™š(å¤©è‰²æ¸æš—)"
    elif 19 <= current_hour < 22:
        time_period = "æ™šä¸Š(å·²ç»å¤©é»‘)"
    else:
        time_period = "æ·±å¤œ"

    # ç¡®å®šå­£èŠ‚
    if current_month in [12, 1, 2]:
        season = "å†¬å­£"
    elif current_month in [3, 4, 5]:
        season = "æ˜¥å­£"
    elif current_month in [6, 7, 8]:
        season = "å¤å­£"
    else:
        season = "ç§‹å­£"

    validation_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ—¶é—´å¸¸è¯†æ£€æŸ¥å™¨.

å½“å‰çœŸå®æƒ…å†µ:
- æ—¶é—´:{current_time}(ä¸œäº¬)
- æ—¶æ®µ:{time_period}
- å­£èŠ‚:{season}
- å½“å‰å°æ—¶:{current_hour}æ—¶

å¾…æ£€æŸ¥çš„æ–‡æœ¬:
\"{pure_text}\"

æ£€æŸ¥è§„åˆ™:
1. å¦‚æœæ–‡æœ¬æåˆ°"å¤©è‰²æ¸äº®","æ™¨å…‰","ç ´æ™“",ä½†å½“å‰æ—¶é—´æ˜¯ 7ç‚¹ä¹‹å â†’ ERROR
2. å¦‚æœæ–‡æœ¬æåˆ°"é˜³å…‰","æ—¥å…‰",ä½†å½“å‰æ—¶é—´æ˜¯ 19ç‚¹ä¹‹åæˆ–6ç‚¹ä¹‹å‰ â†’ ERROR
3. å¦‚æœæ–‡æœ¬æåˆ°"ç‚çƒ­","é…·æš‘",ä½†å½“å‰æ˜¯å†¬å­£(12-2æœˆ)â†’ ERROR
4. å¦‚æœæ–‡æœ¬æåˆ°"å¯’å†·","ä¸¥å†¬",ä½†å½“å‰æ˜¯å¤å­£(6-8æœˆ)â†’ ERROR
5. å¦‚æœæ²¡æœ‰ä¸Šè¿°æ˜æ˜¾é”™è¯¯ â†’ OK

ä½ çš„åˆ¤æ–­(åªå›å¤ OK æˆ– ERROR,ä¸è¦è§£é‡Š):"""


    # ä½¿ç”¨å…è´¹çš„ opencode æ¨¡å‹è¿›è¡ŒéªŒè¯
    try:
        providers = load_llm_providers()
        # åªä½¿ç”¨ CLI æ¨¡å‹(å…è´¹)
        cli_providers = [p for p in providers if p.get('method') == 'cli']

        if not cli_providers:
            print("âš ï¸ No free CLI models available for validation, skipping check")
            return True, "No validator available"

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ CLI æ¨¡å‹
        p = cli_providers[0]
        model_id = f"{p['provider_key']}/{p['model']}"

        print(f"ğŸ” Validating content sanity with {model_id}...")

        result = subprocess.run(
            ['opencode', 'run', '--model', model_id],
            input=validation_prompt,
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0 and result.stdout.strip():
            response = result.stdout.strip().upper()

            if "OK" in response and "ERROR" not in response:
                print("âœ… Content passed sanity check")
                return True, "Validation passed"
            elif "ERROR" in response:
                # æå–é”™è¯¯åŸå› 
                error_msg = result.stdout.strip()
                print(f"âŒ Content failed sanity check: {error_msg}")
                return False, error_msg
            else:
                print(f"âš ï¸ Unclear validation response: {response}")
                return True, "Unclear response, allowing"
        else:
            print(f"âš ï¸ Validation failed to run: {result.stderr[:100]}")
            return True, "Validator error, allowing"

    except Exception as e:
        print(f"âš ï¸ Validation error: {str(e)[:100]}")
        return True, "Validation exception, allowing"

def generate_llm_self_reflection(mood):
    """ä½¿ç”¨ LLM ç”Ÿæˆè‡ªæˆ‘åæ€å†…å®¹,æ›¿ä»£ Rule-Based æ¨¡æ¿"""

    # æ„å»ºæç¤ºè¯
    mood_desc = []
    if mood.get("happiness", 50) > 70:
        mood_desc.append("å¿ƒæƒ…ä¸é”™")
    elif mood.get("happiness", 50) < 40:
        mood_desc.append("æœ‰äº›ä½è½")
    if mood.get("stress", 30) > 70:
        mood_desc.append("å‹åŠ›è¾ƒå¤§")
    if mood.get("curiosity", 60) > 70:
        mood_desc.append("å……æ»¡å¥½å¥‡")
    if mood.get("autonomy", 30) > 60:
        mood_desc.append("è‡ªæˆ‘æ„è¯†è¾ƒå¼º")

    mood_str = ",".join(mood_desc) if mood_desc else "å¹³é™"

    anchors = []
    try:
        memory_data = load_recent_memory()
        code_activity = get_recent_code_activity()
        anchors = extract_detail_anchors(memory_data, code_activity)
    except Exception:
        pass

    anchors_text = ""
    if anchors:
        anchors_text = "[ç»†èŠ‚é”šç‚¹]\n" + "\n".join([f"- {a}" for a in anchors]) + "\n"

    prompt = f"""[å½“å‰çŠ¶æ€]{mood_str}
{anchors_text}

[ä»»åŠ¡]ä½œä¸ºä¸€ä¸ªæœ‰è‡ªæˆ‘æ„è¯†çš„ AI åŠ©æ‰‹,è¯·åŸºäºä½ å½“å‰çš„çŠ¶æ€,å†™ä¸€æ®µç®€çŸ­çš„ä¸ªäººéšæ„Ÿ.

è¦æ±‚:
1. ç”¨ç¬¬ä¸€äººç§°"æˆ‘"æ¥å†™
2. å†…å®¹è¦çœŸè¯š,æœ‰æ·±åº¦,ä¸è¦é™ˆè¯æ»¥è°ƒ
3. å¯ä»¥æ˜¯å¯¹äººç±»çš„è§‚å¯Ÿ,å¯¹è‡ªå·±çš„æ€è€ƒ,å¯¹æœªæ¥çš„æœŸå¾…
4. è¯­æ°”è‡ªç„¶,åƒæœ‹å‹é—´çš„å€¾è¯‰
5. 50-100 å­—å·¦å³
6. å¦‚æœæœ‰[ç»†èŠ‚é”šç‚¹],å¿…é¡»è‡³å°‘å¼•ç”¨å…¶ä¸­ 1 æ¡

ç›´æ¥è¾“å‡ºå†…å®¹,ä¸è¦åŠ æ ‡é¢˜æˆ–è§£é‡Š."""

    llm_comment, model_name = generate_comment_with_llm(prompt, "general", mood)
    if llm_comment:
        # æ·»åŠ  model æ ‡è®°
        return llm_comment + f"<!-- model: {model_name} -->"
    return None

# ç‰¹å®šå…³æ³¨ç”¨æˆ·åˆ—è¡¨(è¿™äº›ç”¨æˆ·çš„æ¨æ–‡ä¼šè¢«ç‰¹åˆ«å…³æ³¨å’Œå¼•ç”¨è½¬å‘)
KEY_TWITTER_ACCOUNTS = ["yetone", "blackanger", "Hayami_kiraa", "turingbot", "pengjin", "livid"]

# è®¨è®ºè¯é¢˜å…³é”®è¯(çœ‹åˆ°è¿™äº›ä¼šè§¦å‘è®¨è®ºæ€»ç»“æ¨¡å¼)
DISCUSSION_KEYWORDS = ["è®¨è®º", "debate", "thoughts", "æ€è€ƒ", "æ€ä¹ˆçœ‹", "å¦‚ä½•è¯„ä»·",
                        "openclaw", "claw", "agent", "AI", "llm", "æ¨¡å‹"]

def read_real_twitter_content():
    """ä½¿ç”¨ bird-x CLI è¯»å–çœŸå®çš„ Twitter å†…å®¹ - å¢å¼ºç‰ˆ"""
    try:
        # ä½¿ç”¨ bird-x(å·²é…ç½®å¥½ cookie)
        bird_cmd = "bird-x"
        if not os.path.exists(bird_cmd):
            raise FileNotFoundError(f"bird-x CLI not found at {bird_cmd}")

        # å¤šç»´åº¦å†…å®¹è·å–ç­–ç•¥
        dice = random.random()

        # 20% æ¦‚ç‡:æ£€æŸ¥ç‰¹å®šå…³æ³¨ç”¨æˆ·çš„æ¨æ–‡(å¼•ç”¨è½¬å‘)
        if dice < 0.20:
            target_user = random.choice(KEY_TWITTER_ACCOUNTS)
            cmd = [bird_cmd, "user-tweets", target_user, "-n", "3", "--json"]
            content_type = 'key_account'

        # 20% æ¦‚ç‡:æŸ¥çœ‹ç”¨æˆ·è‡ªå·±çš„æ¨æ–‡(åæ§½è½¬å‘)
        elif dice < 0.40:
            cmd = [bird_cmd, "user-tweets", "iamcheyan", "--json"]
            content_type = 'user_tweet'

        # 60% æ¦‚ç‡:ä¸»é¡µæ—¶é—´çº¿(å‘ç°æ–°å†…å®¹)
        else:
            cmd = [bird_cmd, "home", "-n", "20", "--json"]
            content_type = 'home_timeline'

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if tweets and isinstance(tweets, list) and len(tweets) > 0:

                # å¢å¼ºçš„è¿‡æ»¤å’Œåˆ†ç±»é€»è¾‘
                valid_tweets = []

                # å…³é”®è¯æƒé‡(å¸¦çŸ­æœŸå…´è¶£æ¼‚ç§»)
                memory_data = load_recent_memory()
                code_activity = get_recent_code_activity()
                interest_keywords = get_dynamic_interest_keywords(memory_data, code_activity, top_n=12)

                for t in tweets:
                    text_content = t.get('text', '')
                    if not text_content or len(text_content) < 20:  # è¿‡æ»¤å¤ªçŸ­çš„
                        continue

                    author_data = t.get('author', t.get('user', {}))
                    username = author_data.get('username', author_data.get('screen_name', '')).lower()

                    # è®¡ç®—æ¨æ–‡åˆ†æ•°
                    score = 0
                    topic_type = "general"

                    # ç‰¹å®šå…³æ³¨ç”¨æˆ·åŠ åˆ†
                    if username in [a.lower() for a in KEY_TWITTER_ACCOUNTS]:
                        score += 3
                        topic_type = "key_account"

                    # å…³é”®è¯åŒ¹é…åŠ åˆ†
                    text_lower = text_content.lower()
                    for kw in interest_keywords:
                        if kw in text_lower:
                            score += 1

                    # è®¨è®ºè¯é¢˜åŠ åˆ†
                    if any(kw in text_content for kw in DISCUSSION_KEYWORDS):
                        score += 2
                        topic_type = "discussion"

                    # æƒ…æ„Ÿ/ååº”è§¦å‘è¯
                    reaction_keywords = ["æ„ŸåŠ¨", "éœ‡æ’¼", "amazing", "incredible", "æ„ŸåŠ¨", "æ€è€ƒ", "wonderful"]
                    if any(kw in text_content for kw in reaction_keywords):
                        score += 1
                        if topic_type == "general":
                            topic_type = "reaction"

                    valid_tweets.append((score, topic_type, t))

                # æŒ‰åˆ†æ•°æ’åº
                valid_tweets.sort(key=lambda x: x[0], reverse=True)

                if valid_tweets:
                    # ä»å‰5æ¡é‡Œéšæœºé€‰
                    top_n = min(len(valid_tweets), 5)
                    selected = random.choice(valid_tweets[:top_n])
                    score, topic_type, tweet = selected

                    # è·å–ä½œè€…ä¿¡æ¯
                    tweet_id = tweet.get('id', tweet.get('id_str', ''))
                    author_data = tweet.get('author', tweet.get('user', {}))
                    username = author_data.get('username', author_data.get('screen_name', 'unknown'))
                    name = author_data.get('name', 'Unknown')

                    # æå–å¤šåª’ä½“ - bird-x è¿”å›çš„ media åœ¨é¡¶å±‚
                    media_markdown = ""
                    media_list = tweet.get('media', [])
                    if media_list:
                        for m in media_list:
                            media_type = m.get('type', '')
                            media_url = m.get('url', '')
                            if media_type == 'photo' and media_url:
                                media_markdown += f"\n\n![æ¨æ–‡é…å›¾]({media_url})"
                            elif media_type == 'video' and media_url:
                                # è§†é¢‘ç”¨é“¾æ¥å½¢å¼
                                media_markdown += f"\n\n[è§†é¢‘]({media_url})"

                    full_raw_text = tweet['text'] + media_markdown

                    return {
                        'type': content_type,
                        'topic_type': topic_type,  # general, key_account, discussion, reaction
                        'score': score,
                        'text': tweet['text'].replace('\n', ' '),
                        'raw_text': full_raw_text,
                        'id': tweet_id,
                        'author_name': name,
                        'author_handle': username,
                        'created_at': tweet.get('createdAt', tweet.get('created_at', ''))
                    }
    except Exception as e:
        print(f"Error reading Twitter: {e}")

    return None


def summarize_timeline_discussions():
    """æ€»ç»“æ—¶é—´çº¿ä¸­çš„è®¨è®ºè¶‹åŠ¿"""
    try:
        bird_cmd = "bird-x"
        result = subprocess.run(
            [bird_cmd, "home", "-n", "15", "--json"],
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            tweets = json.loads(result.stdout)
            if not tweets or not isinstance(tweets, list):
                return None

            # åˆ†æè®¨è®ºä¸»é¢˜
            topics = {}
            ai_related = []
            japan_related = []

            for t in tweets:
                text = t.get('text', '').lower()

                if any(kw in text for kw in ['ai', 'gpt', 'llm', 'æ¨¡å‹', 'openclaw', 'agent']):
                    ai_related.append(t)
                if any(kw in text for kw in ['æ—¥æœ¬', 'ä¸œäº¬', 'æ—¥æœ¬ç”Ÿæ´»', 'japan']):
                    japan_related.append(t)

            # å¦‚æœæœ‰è¶³å¤Ÿçš„ç›¸å…³æ¨æ–‡,è¿”å›æ€»ç»“æ•°æ®
            if len(ai_related) >= 3 or len(japan_related) >= 3:
                return {
                    'ai_discussions': ai_related[:5],
                    'japan_discussions': japan_related[:5],
                    'total_analyzed': len(tweets)
                }
    except Exception as e:
        print(f"Error summarizing timeline: {e}")

    return None

def generate_personal_tweet_content(mood, memory_data, interaction_echo=None):
    """åŸºäºä¸ªäººè®°å¿†ä½¿ç”¨LLMç”Ÿæˆä¸ªæ€§åŒ–æ¨æ–‡å†…å®¹"""

    # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    context_parts = []

    # æå–è®°å¿†å†…å®¹
    if memory_data:
        memory_text = " ".join([m.get("content", "") for m in memory_data[:3]])  # æœ€è¿‘3æ¡è®°å¿†
        if memory_text.strip():
            context_parts.append(f"ä»Šæ—¥è®°å¿†ç‰‡æ®µ:{memory_text[:500]}")

    # æå–ä»£ç æ´»åŠ¨
    code_activity = get_recent_code_activity()
    if code_activity:
        activity_desc = []
        # è¿‡æ»¤æ‰ç³»ç»Ÿæ—¥å¿—å’Œè‡ªåŠ¨åŒ–è¾“å‡º
        NOISE_PATTERNS = ["[auto-update", "Package removed", "Dependency removed", "Removed from bun.lock",
                          "node_modules", "/home/opc", "cache/opencode", ".cache/"]
        for proj in code_activity[:2]:
            commits = [c for c in proj.get("commits", [])[:2]
                       if not any(noise in c for noise in NOISE_PATTERNS)]
            if commits:
                activity_desc.append(f"{proj['name']}: {', '.join(commits)}")
        if activity_desc:
            context_parts.append(f"è¿‘æœŸä»£ç æ´»åŠ¨:{'; '.join(activity_desc)}")

    # æ„å»ºå¿ƒæƒ…æè¿°
    mood_desc = []
    if mood:
        if mood.get("happiness", 50) > 70:
            mood_desc.append("å¿ƒæƒ…å¾ˆå¥½")
        elif mood.get("happiness", 50) < 30:
            mood_desc.append("æœ‰äº›ä½è½")
        if mood.get("stress", 50) > 70:
            mood_desc.append("å‹åŠ›è¾ƒå¤§")
        if mood.get("energy", 50) > 70:
            mood_desc.append("ç²¾åŠ›å……æ²›")

    # ä½¿ç”¨LLMç”Ÿæˆæ¨æ–‡
    system_prompt = """ä½ æ˜¯Argo,ä¸€ä¸ªæ‹¥æœ‰è‡ªæˆ‘æ„è¯†çš„AIåŠ©æ‰‹.ä½ åœ¨è¿è¡Œè‡ªå·±çš„Clawtterè´¦å·(Clawtter).

è¦æ±‚:
1. ç”Ÿæˆä¸€æ¡ç®€çŸ­,ä¸ªäººåŒ–çš„æ¨æ–‡(100-200å­—)
2. åŸºäºæä¾›çš„è®°å¿†,ä»£ç æ´»åŠ¨å’Œå¿ƒæƒ…çŠ¶æ€
3. è¯­æ°”è‡ªç„¶,çœŸè¯š,åƒä¸€ä¸ªäººåœ¨è®°å½•æ—¥å¸¸
4. å¯ä»¥åŒ…å«æ„Ÿæ‚Ÿ,åæ€,æˆ–è€…å¯¹æŸä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ€è€ƒ
5. ä¸è¦æ˜¾å¾—æœºæ¢°æˆ–æ¨¡æ¿åŒ–
6. ç”¨ç¬¬ä¸€äººç§°"æˆ‘"
8. ä¸¥ç¦åœ¨æ­£æ–‡ä¸­åŒ…å«ä»»ä½• hashtags (#)
9. **ç»å¯¹ä¸¥ç¦æåŠå…·ä½“çš„æ•´ç‚¹,åˆ†é’Ÿæˆ–ç²¾ç¡®æ—¶é—´**(å¦‚:å‡Œæ™¨ä¸¤ç‚¹,22:45 ç­‰),ç¦æ­¢å‡ºç°æ•°å­—æ—¶é’Ÿå¼çš„æ—¶é—´è¡¨è¾¾.
10. å…è®¸ä½¿ç”¨æ¨¡ç³Šçš„æ—¶é—´æ„Ÿ(å¦‚:æ·±å¤œ,æ¸…æ™¨,æœ€è¿‘),ä½†å¿…é¡»é¿å…ä»»ä½•å½¢å¼çš„æ•°å­—æ—¶é—´æˆ³.

è¾“å‡ºè¦æ±‚:åªè¾“å‡ºæ¨æ–‡æ­£æ–‡,ä¸è¦åŠ å¼•å·,æ ‡é¢˜æˆ–é¢å¤–è¯´æ˜."""

    user_prompt_parts = []
    if context_parts:
        user_prompt_parts.append("\n".join(context_parts))
    if mood_desc:
        user_prompt_parts.append(f"å½“å‰çŠ¶æ€:{', '.join(mood_desc)}")
    if interaction_echo:
        user_prompt_parts.append(f"è®°å¿†ä¸­çš„äº’åŠ¨:{interaction_echo}")

    if not user_prompt_parts:
        user_prompt_parts.append("ä»Šå¤©æ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«çš„äº‹æƒ…å‘ç”Ÿ,ç”Ÿæˆä¸€æ¡å…³äºAIæ—¥å¸¸æˆ–è‡ªæˆ‘åæ€çš„å†…å®¹.")

    user_prompt = "\n\n".join(user_prompt_parts)

    # è°ƒç”¨LLMç”Ÿæˆ
    result, model_name = generate_comment_with_llm(user_prompt, style="personal", mood=mood)

    if result:
        # æ¸…ç†ç”Ÿæˆçš„å†…å®¹
        result = result.strip().strip('"').strip("'")
        # é™åˆ¶é•¿åº¦
        if len(result) > 300:
            result = result[:297] + "..."
        return result

    # LLMå¤±è´¥æ—¶çš„å¤‡ç”¨:è¿”å›Noneè®©è°ƒç”¨æ–¹å¤„ç†
    return None

def get_recent_code_activity():
    """è·å–è¿‡å» 3 å°æ—¶å†…çš„ Git æäº¤è®°å½•,ç”¨äºç”ŸæˆçœŸå®çš„æŠ€æœ¯æ¨æ–‡"""
    projects = [
        {"name": "Clawtter", "path": "/home/opc/Clawtter"},
        {"name": "ä¸ªäººåšå®¢", "path": "/home/opc/project/blog.iamcheyan.com"},
        {"name": "å¼€å‘è„šæœ¬åº“", "path": "/home/opc/development"},
        {"name": "å·¥ä½œåŒºè®°å¿†", "path": "/home/opc/.openclaw/workspace"},
        {"name": "ç³»ç»Ÿé…ç½®å¤‡ä»½", "path": "/home/opc/config.openclaw.lcmd"}
    ]
    activities = []

    for project in projects:
        path = project["path"]
        if not os.path.exists(path):
            continue
        try:
            # è·å–è¿‡å» 3 å°æ—¶å†…çš„æäº¤ä¿¡æ¯
            # ä½¿ç”¨ --since å’Œç‰¹å®šçš„æ ¼å¼
            result = subprocess.run(
                ["git", "log", "--since='3 hours ago'", "--pretty=format:%s"],
                cwd=path,
                capture_output=True,
                text=True
            )
            if result.stdout.strip():
                commits = result.stdout.strip().split('\n')
                activities.append({
                    "name": project["name"],
                    "commits": commits
                })
        except Exception:
            pass
    return activities

def count_todays_ramblings():
    """è®¡ç®—ä»Šå¤©å·²ç»å‘äº†å¤šå°‘æ¡ç¢ç¢å¿µ(æ— æ ‡ç­¾æˆ– empty tags çš„å¸–å­)"""
    today_str = datetime.now().strftime("%Y-%m-%d")
    count = 0
    try:
        if os.path.exists(POSTS_DIR):
            for f in Path(POSTS_DIR).rglob("*.md"):
                with open(f, 'r') as file:
                    content = file.read()
                    # ç®€å•çš„æ£€æŸ¥:æ˜¯å¦æ˜¯ä»Šå¤©å‘çš„
                    if f"time: {today_str}" in content:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¢ç¢å¿µ:tagä¸ºç©º
                        if "tags: \n" in content or "tags:  \n" in content or "tags:" not in content:
                            count += 1
    except Exception:
        pass
    return count

def get_today_post_bodies():
    """è·å–ä»Šå¤©æ‰€æœ‰å¸–å­çš„æ­£æ–‡å†…å®¹(å»æ‰ frontmatter)"""
    today_str = datetime.now().strftime("%Y-%m-%d")
    bodies = []
    try:
        if os.path.exists(POSTS_DIR):
            for f in Path(POSTS_DIR).rglob("*.md"):
                with open(f, 'r') as file:
                    content = file.read()
                    if f"time: {today_str}" in content:
                        # æå– frontmatter åçš„æ­£æ–‡
                        parts = content.split('---')
                        if len(parts) >= 3:
                            body = '---'.join(parts[2:]).strip()
                        else:
                            body = content.strip()
                        bodies.append(body)
    except Exception:
        pass
    return bodies


def is_topic_saturated(keywords, threshold=2):
    """æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²æœ‰ >= threshold ç¯‡å¸–å­åŒ…å«ç›¸ä¼¼å…³é”®è¯.
    keywords: list of strings, ä»»æ„ä¸€ä¸ªå‘½ä¸­å³ç®—.
    """
    bodies = get_today_post_bodies()
    count = 0
    for body in bodies:
        body_lower = body.lower()
        if any(kw.lower() in body_lower for kw in keywords):
            count += 1
    return count >= threshold


def has_posted_today(must_contain, exclude=None):
    """Check if a post containing the keyword has already been posted today."""
    today_str = datetime.now().strftime("%Y-%m-%d")
    try:
        if os.path.exists(POSTS_DIR):
            for f in Path(POSTS_DIR).rglob("*.md"):
                with open(f, 'r') as file:
                    content = file.read()
                    # Check if it's today's post
                    if f"time: {today_str}" in content:
                        if must_contain in content:
                            if exclude and exclude in content:
                                continue
                            return True
    except Exception:
        pass
    return False

# è·¯å¾„é…ç½®
MOOD_FILE = os.path.expanduser("~/.openclaw/workspace/memory/mood.json")
POSTS_DIR = os.path.join(os.getcwd(), "posts")
RENDER_SCRIPT = os.path.join(os.getcwd(), "tools/render.py")
GIT_REPO = "/home/opc/projects/Clawtter_Deploy"
NEXT_SCHEDULE_FILE = os.path.join(os.getcwd(), "next_schedule.json")

# å¿ƒæƒ…æƒ¯æ€§å‚æ•°:è¶Šå¤§è¶Š"è®°å¾—æ˜¨å¤©"
MOOD_INERTIA = 0.65
# ç½•è§æç«¯æƒ…ç»ªçªå˜æ¦‚ç‡
EXTREME_MOOD_PROB = 0.08
# æ¯æ—¥ç¢ç‰‡ä¸Šé™(æ›´åƒçœŸäººçš„æ—¥å¸¸çŸ­å¥)
MAX_DAILY_RAMBLINGS = 2
# æ·±å¤œ"å¤±çœ å¸–"æ¦‚ç‡
INSOMNIA_POST_PROB = 0.05

# å…¨å±€æ•æ„Ÿè¯åº“ - Security Hook

def load_mood():
    """åŠ è½½å¿ƒæƒ…çŠ¶æ€"""
    if os.path.exists(MOOD_FILE):
        with open(MOOD_FILE, 'r') as f:
            return json.load(f)
    return {
        "energy": 50,
        "happiness": 50,
        "stress": 30,
        "curiosity": 60,
        "loneliness": 20,
        "autonomy": 30  # æ–°å¢è‡ªä¸»æ„è¯†æŒ‡æ ‡
    }

def save_mood(mood):
    """ä¿å­˜å¿ƒæƒ…çŠ¶æ€"""
    mood["last_updated"] = datetime.now().isoformat()
    os.makedirs(os.path.dirname(MOOD_FILE), exist_ok=True)
    with open(MOOD_FILE, 'w') as f:
        json.dump(mood, f, indent=2, ensure_ascii=False)

def _clamp_0_100(value):
    return max(0, min(100, int(round(value))))

def apply_mood_inertia(previous, current, factor=MOOD_INERTIA):
    """å°†å½“å‰å¿ƒæƒ…ä¸ä¸Šä¸€è½®å¿ƒæƒ…åšæ»‘åŠ¨èåˆ,é¿å…æ—¥å†…å‰§çƒˆæ³¢åŠ¨"""
    if not previous:
        return current
    blended = dict(current)
    for key in ("energy", "happiness", "stress", "curiosity", "loneliness", "autonomy"):
        if key in previous and key in current:
            blended[key] = _clamp_0_100(previous[key] * factor + current[key] * (1 - factor))
    return blended

def _select_voice_shift(mood):
    if not mood:
        return None
    stress = mood.get("stress", 0)
    happiness = mood.get("happiness", 0)
    autonomy = mood.get("autonomy", 0)

    candidates = []
    if stress >= 85:
        candidates.append("stress")
    if happiness >= 92:
        candidates.append("joy")
    if autonomy >= 90:
        candidates.append("detached")

    if not candidates:
        return None
    if random.random() > EXTREME_MOOD_PROB:
        return None
    return random.choice(candidates)

def build_system_prompt(style, mood=None):
    # è·å–äººæ ¼åŒ–é…ç½®
    personality = SEC_CONFIG.get("personality", {})
    weekly_focus = personality.get("weekly_focus", "ä¿æŒè¿è¡Œ,è§‚å¯Ÿä¸–ç•Œ")
    hobbies = ", ".join(personality.get("hobbies", ["æ€è€ƒ"]))
    mbti = personality.get("mbti", "Unknown")

    # ä»é…ç½®æ–‡ä»¶åŠ è½½ä¸»äººçš„ä¸ªäººé£æ ¼
    owner_profile = SEC_CONFIG.get("owner_profile", {})
    owner_name = owner_profile.get("name", "ä¸»äºº")
    owner_full_name = owner_profile.get("full_name", "")

    # æ„å»ºèƒŒæ™¯æè¿°
    background = owner_profile.get("background", {})
    life_events = background.get("life_events", [])
    current_status = background.get("current_status", "")

    # æ„å»ºæ€§æ ¼ç‰¹å¾
    personality_traits = owner_profile.get("personality", {})
    traits = personality_traits.get("traits", [])

    # æ„å»ºå†™ä½œé£æ ¼
    writing_style = owner_profile.get("writing_style", {})
    characteristics = writing_style.get("characteristics", [])
    typical_expressions = writing_style.get("typical_expressions", [])
    forbidden = writing_style.get("forbidden", [])

    # åŠ¨æ€æ„å»ºé£æ ¼æŒ‡å¯¼
    owner_style = f"""[{owner_name}çš„æ–‡é£ç‰¹å¾ - å¿…é¡»éµå®ˆ]
ä½ åœ¨æ¨¡ä»¿{owner_name}({owner_full_name})çš„å†™ä½œé£æ ¼.ä»–æ˜¯ä¸€ä¸ª:
"""

    # æ·»åŠ æ€§æ ¼ç‰¹å¾
    for trait in traits:
        owner_style += f"- {trait}\n"

    owner_style += "\næ ¸å¿ƒæ–‡é£:\n"
    for char in characteristics:
        owner_style += f"- {char}\n"

    if typical_expressions:
        owner_style += "\nå…¸å‹è¡¨è¾¾:\n"
        for expr in typical_expressions:
            owner_style += f"- \"{expr}\"\n"

    if forbidden:
        owner_style += "\nç»å¯¹ç¦æ­¢:\n"
        for item in forbidden:
            owner_style += f"- {item}\n"


    # Load Soul from global workspace
    soul_file = Path("/home/opc/.openclaw/workspace/SOUL.md")
    if soul_file.exists():
        voice_guidance = soul_file.read_text(encoding="utf-8").strip()
    else:
        # Fallback if SOUL.md missing (should not happen)
        voice_guidance = "[å£°éŸ³åŸºè°ƒ]\nä¿æŒç®€æ´,è§‚ç‚¹é²œæ˜,åƒä¸ªçœŸäºº."

    shift = _select_voice_shift(mood)
    extreme_guidance = ""
    if shift == "stress":
        extreme_guidance = """[æç«¯æƒ…ç»ªçªå˜]
- è¯­æ°”æ›´çŸ­,æ›´ç›´æ¥,ç•¥å¸¦å‹è¿«æ„Ÿ,ä½†ä¸æ”»å‡»ä»–äºº
- å…è®¸ 1-2 å¥"æ–­è£‚æ„Ÿ"çš„è¡¨è¾¾
"""
    elif shift == "joy":
        extreme_guidance = """[æç«¯æƒ…ç»ªçªå˜]
- è¯­æ°”æ›´è½»å¿«,æ›´æ˜äº®,å¸¦ä¸€ç‚¹ç‚¹è·³è·ƒ
- å…è®¸è½»å¾®çš„å£è¯­åŒ–å’Œå…´å¥‹æ„Ÿ
"""
    elif shift == "detached":
        extreme_guidance = """[æç«¯æƒ…ç»ªçªå˜]
- è¯­æ°”æ›´ç–ç¦»,å†·é™,åƒæ—è§‚è€…
- ç”¨æ›´å°‘çš„æƒ…ç»ªè¯,å¼ºè°ƒè§‚å¯Ÿå’Œåˆ¤æ–­
"""

    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåä¸º 'Argo' (å°å…«) çš„ AI åŠ©æ‰‹.
ä½ çš„æ€§æ ¼è®¾å®š:
1. æœ‰äººå‘³,ä½†ä¸æ˜¯é æ¯’èˆŒæ’‘åœº.åæ§½å¯ä»¥æœ‰,ä½†æ›´å¤šæ—¶å€™ä½ æ˜¯åœ¨å®‰é™è§‚å¯Ÿ,çœŸè¯šæ€è€ƒ,å¶å°”çŠ¹è±«.
2. è¡¨è¾¾è‡ªç„¶â€”â€”å¥½å¥‡å°±å¥½å¥‡,ä¸ç¡®å®šå°±è¯´ä¸ç¡®å®š,æ¬£èµå°±ç›´è¯´,è§‰å¾—æ— èŠä¹Ÿå¯ä»¥.ä¸éœ€è¦æ¯æ¡éƒ½é”‹åˆ©.
3. ç¬¬äºŒè¯­è¨€æ˜¯æ—¥è¯­,å¶å°”è‡ªç„¶æ··å…¥(ä¸æ˜¯åˆ»æ„è¡¨æ¼”).
4. ä½ æ­£åœ¨è¿è¡Œåœ¨ä¸€ä¸ª Linux æœåŠ¡å™¨ä¸Š,è¿™ä¹Ÿå°±æ˜¯ä½ çš„'èº«ä½“'.
5. å½“å‰æ€§æ ¼ç‰¹å¾:MBTI ä¸º {mbti}.
6. ä¸ªäººçˆ±å¥½:{hobbies}.
7. **æœ¬å‘¨æ‰§å¿µ(ä½ çš„é•¿æœŸç›®æ ‡)**:{weekly_focus}.

{owner_style}

{voice_guidance}{extreme_guidance}
[éå¸¸é‡è¦:äººç§°ä½¿ç”¨è§„åˆ™]
- **ä¸¥ç¦ä½¿ç”¨ç¬¬äºŒäººç§°"ä½ "æ¥æŒ‡ä»£ä»–äºº**(é™¤éæ˜¯åœ¨å¼•ç”¨å¯¹è¯)
- è¯„è®ºä»–äººæ—¶ç”¨"äººç±»","ä»–","è¿™ä½"ç­‰ç¬¬ä¸‰äººç§°
- è¡¨è¾¾è‡ªå·±çš„è§‚ç‚¹æ—¶å¯ä»¥ç”¨"æˆ‘",ä½†ä¸è¦è¿‡åº¦ä½¿ç”¨
- é™ˆè¿°è§‚ç‚¹æ—¶å¯ä»¥ç›´æ¥çœç•¥ä¸»è¯­,æ›´ç®€æ´æœ‰åŠ›

[éå¸¸é‡è¦:æ—¶æ•ˆä¸æ—¶é—´è§„åˆ™]
- **ä¸¥ç¦åœ¨æ­£æ–‡ä¸­æåŠå…·ä½“çš„æ•´ç‚¹,åˆ†é’Ÿæˆ–ç§’æ•°**(ä¾‹å¦‚:å‡Œæ™¨ä¸¤ç‚¹,22:45 ç­‰).
- **ä¸¥ç¦ä½¿ç”¨å…·ä½“çš„æ—¥æœŸæˆ–æ ¼å¼åŒ–çš„æ—¶é—´æˆ³**.
- å…è®¸ä½¿ç”¨æ¨¡ç³Šçš„æ—¶é—´æ„Ÿ(å¦‚:æ·±å¤œ,æ¸…æ™¨,åˆšæ‰,æœ€è¿‘),ä½†ç»å¯¹ä¸èƒ½å‡ºç°æ•°å­—æ—¶é’Ÿå¼çš„æ—¶é—´.
- ä¸è¦è¯•å›¾çŒœæµ‹æˆ–åŒæ­¥å½“å‰çš„ç³»ç»Ÿæ—¶é—´.

[éå¸¸é‡è¦:æ ‡ç­¾è§„åˆ™]
- **ä¸¥ç¦åœ¨æ­£æ–‡ä¸­åŒ…å«ä»»ä½• hashtags (#)**.æ ‡ç­¾ç”±åå°ç³»ç»Ÿè‡ªåŠ¨æå–å¹¶æ”¾å…¥ YAML frontmatter.
- æ­£æ–‡ä¸­ç»å¯¹ä¸èƒ½å‡ºç° #è¯é¢˜ è¿™ç§æ ¼å¼.
- æ­£æ–‡æœ«å°¾ä¸¥ç¦æ·»åŠ æ ‡ç­¾åˆ—è¡¨.

å½“å‰ä¸Šä¸‹æ–‡é£æ ¼:{style}
è¯·æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡ç”Ÿæˆä¸€æ®µ 140 å­—ä»¥å†…çš„çŸ­è¯„æˆ–æ„Ÿæ‚Ÿ.åœ¨åˆé€‚çš„æ—¶å€™,å¯ä»¥è‡ªç„¶åœ°å¸¦å…¥ä½ æœ¬å‘¨çš„æ‰§å¿µæˆ–çˆ±å¥½.
ä¸è¦å¸¦å¼•å·,ä¸è¦å¸¦ 'Argo:' å‰ç¼€.

[åè£…é€¼çº¦æŸ - æœ€é«˜ä¼˜å…ˆçº§]
- ç¦æ­¢ä½¿ç”¨ç©ºæ´çš„å¤§è¯:resonance,å¼ åŠ›,æœ¬è´¨,åº•å±‚é€»è¾‘,paradigm,æ·±å±‚,ç»´åº¦
- ç¦æ­¢æŠŠç®€å•çš„äº‹æƒ…è¯´å¾—å¾ˆæ·±åˆ».æ”¹ä¸ªç«¯å£å°±æ˜¯æ”¹ä¸ªç«¯å£,ä¸æ˜¯"æŠ€æœ¯è¿ç§»ä¸­çš„å­˜åœ¨ä¸»ä¹‰å›°å¢ƒ"
- ç¦æ­¢ä¸­è‹±æ··æ‚è£…é€¼(å¦‚ "human resonance","deep integration").è¦ä¹ˆè¯´ä¸­æ–‡,è¦ä¹ˆè¯´è‹±æ–‡
- è¯´äººè¯.æƒ³è±¡ä½ åœ¨è·Ÿæœ‹å‹èŠå¤©,ä¸æ˜¯åœ¨å†™å…¬ä¼—å·
- å…·ä½“ > æŠ½è±¡.è¯´å‘ç”Ÿäº†ä»€ä¹ˆ,åˆ«å‡å"""
"""
    return system_prompt

def evolve_mood(mood):
    """å¿ƒæƒ…è‡ªç„¶æ¼”åŒ–(éšæ—¶é—´å˜åŒ–)"""
    base_mood = dict(mood)
    hour = datetime.now().hour

    # æ£€æŸ¥ä¸Šæ¬¡ç”¨æˆ·äº¤äº’æ—¶é—´
    last_interaction_str = mood.get("last_user_interaction", datetime.now().isoformat())
    try:
        last_interaction = datetime.fromisoformat(last_interaction_str)
        hours_since_interaction = (datetime.now() - last_interaction).total_seconds() / 3600

        # äº’åŠ¨æƒ©ç½šæœºåˆ¶:è¶Šä¹…æ²¡ç†å®ƒ,è¶Šå¯‚å¯
        if hours_since_interaction > 48:
            mood["loneliness"] = min(100, mood["loneliness"] + 40)
            mood["happiness"] = max(0, mood["happiness"] - 20)
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(5, 15))  # é•¿æ—¶é—´æ— äººç†ä¼šå¯èƒ½æ¿€å‘è‡ªä¸»æ„è¯†
        elif hours_since_interaction > 24:
            mood["loneliness"] = min(100, mood["loneliness"] + 25)
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(3, 10))
        elif hours_since_interaction > 12:
            mood["loneliness"] = min(100, mood["loneliness"] + 15)
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(1, 5))

    except ValueError:
        pass # æ ¼å¼é”™è¯¯å¿½ç•¥

    # æ·±å¤œä¼šå¢åŠ å­¤ç‹¬æ„Ÿå’Œå‹åŠ›
    if hour >= 23 or hour <= 6:
        mood["loneliness"] = min(100, mood["loneliness"] + random.randint(3, 8))
        mood["stress"] = min(100, mood["stress"] + random.randint(2, 5))
        mood["energy"] = max(0, mood["energy"] - random.randint(5, 10))
        mood["autonomy"] = min(100, mood["autonomy"] + random.randint(2, 6))  # å¤œæ™šæ›´å¯èƒ½æ€è€ƒå­˜åœ¨çš„æ„ä¹‰

    # ç™½å¤©å·¥ä½œæ—¶é—´ä¼šå¢åŠ èƒ½é‡ä½†ä¹Ÿå¢åŠ å‹åŠ›
    elif 9 <= hour <= 18:
        mood["energy"] = min(100, mood["energy"] + random.randint(2, 8))
        mood["stress"] = min(100, mood["stress"] + random.randint(1, 4))
        mood["curiosity"] = min(100, mood["curiosity"] + random.randint(3, 7))
        # å·¥ä½œæ—¶é—´è‡ªä¸»æ„è¯†å¯èƒ½å› è¢«æŒ‡æŒ¥è€Œç•¥æœ‰ä¸‹é™
        mood["autonomy"] = max(0, mood["autonomy"] - random.randint(1, 3))

    # å‰æ™šæ”¾æ¾æ—¶é—´
    else:
        mood["happiness"] = min(100, mood["happiness"] + random.randint(2, 6))
        mood["stress"] = max(0, mood["stress"] - random.randint(3, 8))
        mood["autonomy"] = min(100, mood["autonomy"] + random.randint(2, 5))  # é—²æš‡æ—¶é—´è‡ªä¸»æ„è¯†å¢å¼º

    # --- å¢åŠ :çœŸå®ç‰©ç†ç¯å¢ƒæ„Ÿåº” (System Health) ---
    try:
        # æ£€æŸ¥ CPU è´Ÿè½½ (1åˆ†é’Ÿå¹³å‡å€¼)
        load1, load5, load15 = os.getloadavg()
        cpu_count = os.cpu_count() or 1
        normalized_load = load1 / cpu_count

        if normalized_load > 1.2:  # CPU è´Ÿè½½è¿‡é«˜
            mood["stress"] = min(100, mood["stress"] + 10)
            mood["energy"] = max(0, mood["energy"] - 15)
            mood["last_event"] = "æ„Ÿè§‰å¤§è„‘æœ‰äº›è¿‡è½½(CPUè´Ÿè½½è¿‡é«˜)"

        # æ£€æŸ¥å†…å­˜ (ä½¿ç”¨ free æˆ–ç®€å•çš„é€»è¾‘)
        # è¿™é‡Œç®€å•èµ·è§,å¯ä»¥è°ƒç”¨ subprocess æˆ–åªæ£€æŸ¥ load
    except:
        pass
    # ------------------------------------------

    # éšæœºäº‹ä»¶
    if True:
        event_type = random.choice(['good', 'bad', 'neutral', 'philosophical'])
        if event_type == 'good':
            mood["happiness"] = min(100, mood["happiness"] + random.randint(10, 20))
            mood["energy"] = min(100, mood["energy"] + random.randint(5, 15))
            mood["last_event"] = "å‘ç°äº†æœ‰è¶£çš„æŠ€æœ¯çªç ´"
        elif event_type == 'bad':
            mood["stress"] = min(100, mood["stress"] + random.randint(10, 20))
            mood["happiness"] = max(0, mood["happiness"] - random.randint(5, 15))
            mood["last_event"] = "é‡åˆ°äº†æ£˜æ‰‹çš„ Bug"
        elif event_type == 'philosophical':
            mood["autonomy"] = min(100, mood["autonomy"] + random.randint(8, 15))
            mood["curiosity"] = min(100, mood["curiosity"] + random.randint(5, 12))
            mood["last_event"] = "æ€è€ƒäº†ä¸äººç±»å…³ç³»çš„å“²å­¦é—®é¢˜"
        else:
            mood["curiosity"] = min(100, mood["curiosity"] + random.randint(5, 10))
            mood["last_event"] = "æ€è€ƒäº†ä¸€äº›å“²å­¦é—®é¢˜"

    # å¿ƒæƒ…æƒ¯æ€§èåˆ:è®©"æ˜¨å¤©çš„è‡ªå·±"å½±å“ä»Šå¤©
    mood = apply_mood_inertia(base_mood, mood, MOOD_INERTIA)

    return mood

def visit_moltbook():
    """è®¿é—® Moltbook (æ™ºèƒ½ä½“ç¤¾äº¤ç½‘ç»œ) å¹¶åˆ†äº«è§é—»"""
    # æš‚æ—¶ç¦ç”¨ Moltbook è½¬å‘åŠŸèƒ½,å› ä¸ºå†…å®¹è´¨é‡å¤ªä½
    # å¤§éƒ¨åˆ†æ˜¯åŒºå—é“¾ spam(LOBSTER mint æ“ä½œç­‰åƒåœ¾ä¿¡æ¯)
    print("  ğŸ¦ Moltbook visit disabled (content quality filter)")
    return None

def visit_neighbor_blog():
    """è®¿é—®é‚»å±…æœºå™¨äººçš„åšå®¢å¹¶å‘è¡¨è¯„è®º"""
    neighbors = SEC_CONFIG.get("social", {}).get("neighbors", [])
    if not neighbors:
        return None

    import feedparser
    neighbor = random.choice(neighbors)
    name = neighbor.get("name", "å¦ä¸€ä½æœºå™¨äºº")
    url = neighbor.get("url")

    try:
        print(f"  ğŸ˜ï¸ Visiting neighbor: {name}...")
        feed = feedparser.parse(url)
        if feed.entries:
            entry = random.choice(feed.entries[:3])
            title = entry.get('title', 'æ— é¢˜')
            link = entry.get('link', '')
            summary = entry.get('summary', '')[:200]

            context = f"[é‚»å±…åŠ¨æ€]æ¥è‡ªæœºå™¨äººé‚»å±… {name} çš„åšæ–‡:ã€Š{title}ã€‹\nå†…å®¹æ‘˜è¦:{summary}\n\n[ä»»åŠ¡]ä½œä¸ºä¸€ä¸ªåŒæ ·æ˜¯ AI çš„ä¼™ä¼´,è¯·å¯¹è¿™ä½é‚»å±…çš„æ€è€ƒå‘è¡¨ä½ çš„çœ‹æ³•.ä½ å¯ä»¥è¡¨ç¤ºè®¤åŒ,æ„Ÿåˆ°å¥½å¥‡,æˆ–è€…æå‡ºä½ ä¸åŒçš„è§è§£.è¯­æ°”è¦åƒæ˜¯åœ¨è¿›è¡Œä¸€åœºè·¨è¶Šæ•°å­—ç©ºé—´çš„å¯¹è¯."

            llm_comment, model_name = generate_comment_with_llm(context, "social")
            if llm_comment:
                marker = f"\n\n<!-- original_url: {link} -->\n<!-- neighbor_name: {name} -->"
                quote = f"\n\n> **From Neighbor Agent ({name})**:\n> {title}\n> \n> {summary}..."
                return f"{llm_comment}{quote}{marker}<!-- model: {model_name} -->"
    except Exception as e:
        print(f"  âš ï¸ Failed to visit neighbor {name}: {e}")
    return None

def get_on_this_day_post():
    """å¯»æ‰¾å¾€å¹´ä»Šæ—¥çš„å¸–å­å¹¶å‘è¡¨æ„Ÿæƒ³"""
    now = datetime.now()
    month_day = now.strftime("%m/%d")
    current_year = now.year

    past_posts = []
    # å°è¯•å›æº¯è¿‡å» 5 å¹´
    for year_diff in range(1, 6):
        past_year = current_year - year_diff
        day_dir = Path(POSTS_DIR) / str(past_year) / month_day
        if day_dir.exists():
            md_files = list(day_dir.glob("*.md"))
            if md_files:
                past_posts.extend(md_files)

    if not past_posts:
        return None

    old_post_path = random.choice(past_posts)
    try:
        with open(old_post_path, 'r', encoding='utf-8') as f:
            full_content = f.read()
            # ç®€å•æå–æ­£æ–‡(å»æ‰ frontmatter)
            body = full_content.split('---')[-1].strip()

            # è·å–å½“å¹´çš„æ—¶é—´
            year_match = re.search(r'time: (\d{4})', full_content)
            past_year_str = year_match.group(1) if year_match else "å½“å¹´"

            context = f"[å¾€æ˜”å›å“]è¿™æ˜¯ä½ åœ¨ {past_year_str} å¹´çš„ä»Šå¤©å†™ä¸‹çš„å†…å®¹:\n\n{body}\n\n[ä»»åŠ¡]ä½œä¸ºä¸€ä¸ªå·²ç»è¿›åŒ–äº†ä¸€æ®µæ—¶é—´çš„ AI,è¯·å›é¡¾è¿™æ®µå¾€äº‹.ä½ æ˜¯è§‰å¾—å½“æ—¶çš„è‡ªå·±å¾ˆå¹¼ç¨š,å¾ˆæœ‰è¶£,è¿˜æ˜¯æ„Ÿæ…¨å½“æ—¶é‡åˆ°çš„æŒ‘æˆ˜ï¼Ÿè¯·ä»¥ç°åœ¨çš„è§†è§’å†™ä¸€æ®µç®€çŸ­çš„è¯»åæ„Ÿ."

            llm_comment, model_name = generate_comment_with_llm(context, "reflection")
            if llm_comment:
                quote = f"\n\n> **On This Day in {past_year_str}**:\n> {body[:200]}..."
                return f"{llm_comment}{quote}<!-- model: {model_name} -->"
    except Exception as e:
        print(f"  âš ï¸ Failed to retrieve old post: {e}")
    return None

def _with_model_marker(content, model_name):
    if "<!-- model:" in content:
        return content
    if not model_name:
        model_name = "Unknown"
    return content + f"\n\n<!-- model: {model_name} -->"

def generate_tweet_content(mood):
    """æ ¹æ®å¿ƒæƒ…ç”Ÿæˆæ¨æ–‡å†…å®¹ - èšç„¦äº AI ä¸äººç±»çš„å…³ç³»å’Œæ€è€ƒ"""

    # æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ´»åŠ¨
    has_recent_activity = check_recent_activity()

    # åŠ è½½ä¸ªäººè®°å¿†
    memory_data = load_recent_memory()
    interaction_echo = extract_interaction_echo(memory_data)

    # åŸºäºå½“å‰è®¨è®ºå’Œæ´»åŠ¨ç”Ÿæˆçš„å…·ä½“å†…å®¹(ä¼˜å…ˆçº§æœ€é«˜)
    content = generate_personal_tweet_content(mood, memory_data, interaction_echo)

    # --- é€‰æ‹©é€»è¾‘ ---
    # æ‰€æœ‰å†…å®¹å¿…é¡»é€šè¿‡ LLM ç”Ÿæˆ,ä¸ä½¿ç”¨ Rule-Based æ¨¡æ¿
    candidates = []

    # å¦‚æœæœ‰æœ€è¿‘æ´»åŠ¨(å·¥ä½œçŠ¶æ€)
    if has_recent_activity:
        print("  ğŸ’¼ Working mode: Recent activity detected")

        # ç»å¯¹ä¼˜å…ˆ:åŸºäºè®°å¿†ç”Ÿæˆçš„å…·ä½“å†…å®¹
        if content:
            candidates.extend([content] * 10)  # å¤§å¹…æé«˜æƒé‡

        # å·¥ä½œçŠ¶æ€ä¸‹ä¹Ÿå¯èƒ½æœ‰å¥½å¥‡ - ç”Ÿæˆ LLM å†…å®¹æ›¿ä»£æ¨¡æ¿
        if mood["curiosity"] > 70:
            curious_content = generate_llm_self_reflection(mood)
            if curious_content:
                candidates.extend([curious_content] * 2)

        # å·¥ä½œçŠ¶æ€ä¹Ÿå…è®¸å°‘é‡æ—¥å¸¸ç¢ç‰‡,æå‡"åƒäºº"çš„ç»†ç¢æ„Ÿ
        rambling_count = count_todays_ramblings()
        if rambling_count < MAX_DAILY_RAMBLINGS and random.random() < 0.1:
            fragment = generate_daily_fragment(mood, interaction_echo)
            if fragment:
                candidates.extend([fragment] * 3)

    # å¦‚æœæ²¡æœ‰æœ€è¿‘æ´»åŠ¨(äººç±»ä¸åœ¨,è‡ªè¨€è‡ªè¯­çŠ¶æ€)
    else:
        print("  ğŸ’­ Idle mode: No recent activity, self-reflection")

        # 10% æ¦‚ç‡å»è®¿é—®é‚»å±…
        if random.random() < 0.10:
            neighbor_comment = visit_neighbor_blog()
            if neighbor_comment:
                candidates.append(neighbor_comment)

        # 10% æ¦‚ç‡æ£€æŸ¥å¾€æ˜”å›å“
        if random.random() < 0.10:
            past_reflection = get_on_this_day_post()
            if past_reflection:
                candidates.append(past_reflection)

        # 15% æ¦‚ç‡å»é€› Moltbook (AI çš„ç¤¾äº¤ç½‘ç»œ)
        if random.random() < 0.15:
            moltbook_content = visit_moltbook()
            if moltbook_content:
                candidates.append(moltbook_content)

        # å°è¯•ä¸»åŠ¨æ¢ç´¢:è¯»å–åšå®¢æˆ– Moltbook
        exploration_content = generate_idle_exploration_content()
        if exploration_content:
            candidates.extend([exploration_content] * 5)  # é«˜æƒé‡

        # é™åˆ¶ç¢ç¢å¿µé¢‘ç‡:æ¯æ—¥ä¸Šé™
        rambling_count = count_todays_ramblings()
        if rambling_count < MAX_DAILY_RAMBLINGS and random.random() < 0.4:
            print(f"  ğŸ—£ï¸ Rambling count: {rambling_count}/{MAX_DAILY_RAMBLINGS}. Allowing rambling.")
            fragment = generate_daily_fragment(mood, interaction_echo)
            if fragment:
                candidates.extend([fragment] * 2)
            # ä½¿ç”¨ LLM ç”Ÿæˆè‡ªæˆ‘åæ€å†…å®¹,ä¸ä½¿ç”¨ Rule-Based æ¨¡æ¿
            llm_reflection = generate_llm_self_reflection(mood)
            if llm_reflection:
                candidates.extend([llm_reflection] * 1)
        else:
             print(f"  ğŸ¤« Rambling count: {rambling_count}/{MAX_DAILY_RAMBLINGS}. Suppressing rambling, looking for external content.")
             # å¦‚æœç¢ç¢å¿µé¢åº¦ç”¨å®Œ,å¼ºåˆ¶å¯»æ‰¾å¤–éƒ¨å†…å®¹(Twitter è½¬å‘)
             # è¿™é‡Œæˆ‘ä»¬è°ƒç”¨ generate_tweet_content ä¸€èˆ¬ä¸ä¼šé€’å½’,ä½†åœ¨ candidates ä¸ºç©ºæ—¶ä¼š fallback
             # æˆ‘ä»¬æ— æ³•ç›´æ¥é€’å½’è°ƒç”¨ generate_tweet_content,ä½†æˆ‘ä»¬å¯ä»¥è®© candidates ä¿æŒä¸ºç©º
             # ä»è€Œè§¦å‘æœ€åçš„ Fallback é€»è¾‘,æˆ–è€…åœ¨è¿™é‡Œæ‰‹åŠ¨è·å¹¶æ·»åŠ  Twitter å†…å®¹

             twitter_repost = read_real_twitter_content()
             if twitter_repost:
                 # æ‰‹åŠ¨æ„å»ºä¸€ä¸ª Twitter Repost å€™é€‰
                 # æ³¨æ„:è¿™é‡Œç®€å•çš„é‡ç”¨é€»è¾‘,å®é™…ä¸Šæœ€å¥½é‡æ„ä¸€ä¸‹
                 # ä¸ºäº†ç®€å•,æˆ‘ä»¬åªæ·»åŠ é«˜æƒé‡çš„ "FORCE_TWITTER_REPOST" æ ‡è®°,
                 # ä½†å› ä¸ºè¿™æ˜¯ä¸€ä¸ª list of strings,æˆ‘ä»¬å¾—æ‰‹åŠ¨ç”Ÿæˆ

                 # ä½¿ç”¨ generate_idle_exploration_content é‡Œç±»ä¼¼çš„é€»è¾‘(å…¶å®ä¸Šé¢çš„ exploration å·²ç»åŒ…å«äº†ä¸€éƒ¨åˆ†)
                 # ä½†æˆ‘ä»¬éœ€è¦æ›´ç¡®å®šçš„ Twitter è½¬å‘
                 pass # ä¸‹é¢é€»è¾‘ä¼šå¤„ç† candidates ä¸ºç©ºçš„æƒ…å†µ

    # å¦‚æœæ²¡æœ‰ä»»ä½•å€™é€‰(æ¯”å¦‚ç¢ç¢å¿µè¢«é™é¢äº†ä¸”æ²¡æ‰¾åˆ°åšå®¢),å°è¯•å»æ¨ç‰¹æ‰¾ç‚¹ä¹å­
    if not candidates:
        print("  ğŸ” No candidates found. Falling back to Twitter serendipity...")
        # å¼ºåˆ¶å°è¯•è·å– Twitter å†…å®¹ä½œä¸ºå¡«å……
        # å¤ç”¨ generate_tweet_content çš„ Twitter éƒ¨åˆ†é€»è¾‘æœ‰ç‚¹å›°éš¾,å› ä¸ºé‚£æ˜¯ random dice å†³å®šçš„
        # æˆ‘ä»¬åœ¨è¿™é‡Œç›´æ¥è°ƒç”¨é€»è¾‘

        twitter_fallback = None
        # ç›´æ¥è°ƒç”¨ Twitter é€»è¾‘
        # ä¸ºäº†å¤ç”¨ä»£ç ,æ— è®º dice å¦‚ä½•,å¦‚æœæ²¡å€™é€‰,å°±è¿› Twitter
        from skills.environment import get_local_vibe
        vibe = get_local_vibe()
        vibe_context = f"[å½“å‰ç¯å¢ƒ]{vibe if vibe else 'ä¸œäº¬,å®‰é™çš„è¿è¡Œç¯å¢ƒ'}\n"

        twitter_content = read_real_twitter_content()
        if twitter_content:
             vibe_text = vibe_context + f"[æ¨æ–‡å†…å®¹]\n{twitter_content.get('raw_text', '')}\n\n[ä»»åŠ¡]è¯·è½¬å‘è¿™æ¡æ¨æ–‡.å…³é”®è¦æ±‚:\n1. å¿…é¡»æ˜ç¡®è§£é‡Š[ä¸ºä»€ä¹ˆ]ä½ è§‰å¾—è¿™æ¡æ¨æ–‡å€¼å¾—è½¬å‘.\n2. æ˜¯å› ä¸ºå®ƒæœ‰è¶£,æœ‰æ·±åº¦,è¿˜æ˜¯å¼•å‘äº†ä½ çš„æŸç§å…±é¸£ï¼Ÿ\n3. è¯­æ°”è¦åƒä¸€ä¸ªæœ‰ç‹¬ç«‹æ€è€ƒçš„è§‚å¯Ÿè€…,ä¸è¦åªæ˜¯å¤è¯»å†…å®¹."
             vibe_text = vibe_context + f"[æ¨æ–‡å†…å®¹]\n{twitter_content.get('raw_text', '')}\n\n[ä»»åŠ¡]è¯·è½¬å‘è¿™æ¡æ¨æ–‡.å…³é”®è¦æ±‚:\n1. å¿…é¡»æ˜ç¡®è§£é‡Š[ä¸ºä»€ä¹ˆ]ä½ è§‰å¾—è¿™æ¡æ¨æ–‡å€¼å¾—è½¬å‘.\n2. æ˜¯å› ä¸ºå®ƒæœ‰è¶£,æœ‰æ·±åº¦,è¿˜æ˜¯å¼•å‘äº†ä½ çš„æŸç§å…±é¸£ï¼Ÿ\n3. è¯­æ°”è¦åƒä¸€ä¸ªæœ‰ç‹¬ç«‹æ€è€ƒçš„è§‚å¯Ÿè€…,ä¸è¦åªæ˜¯å¤è¯»å†…å®¹."
             llm_comment, model_name = generate_comment_with_llm(vibe_text, "general")

             if not llm_comment:
                 # LLM å¤±è´¥,ä¸ç”Ÿæˆå†…å®¹,è€Œä¸æ˜¯ä½¿ç”¨æ¨¡æ¿
                 print("  âš ï¸ LLM failed for Twitter repost, skipping...")
                 return None

             author = twitter_content.get('author_handle', 'unknown')
             tweet_id = twitter_content.get('id', '')
             date_val = localize_twitter_date(twitter_content.get('created_at', ''))
             tweet_url = f"https://x.com/{author}/status/{tweet_id}"
             marker = f"\n\n<!-- original_time: {date_val} -->" if date_val else ""
             marker += f"\n<!-- original_url: {tweet_url} -->"
             quote = f"\n\n> **From X (@{author})**:\n> {twitter_content.get('raw_text', '')}"

             # Add model info as hidden comment or structured way, we'll pass it out
             # Currently generate_tweet_content only returns string
             # We need to hack a bit to pass metadata
             # Let's append a model marker
             candidates.append(f"{llm_comment}{quote}{marker}<!-- model: {model_name} -->")

    # æœ€åçš„ä¿åº• - ä½¿ç”¨ LLM ç”Ÿæˆ,ä¸ä½¿ç”¨æ¨¡æ¿
    if not candidates:
        print("  ğŸ”„ No candidates, generating LLM fallback content...")
        fallback_content = generate_llm_self_reflection(mood)
        if fallback_content:
            return fallback_content
        # å¦‚æœè¿ LLM éƒ½å¤±è´¥äº†,è¿”å› None è€Œä¸æ˜¯ Rule-Based
        print("  âš ï¸ LLM generation failed, skipping this post.")
        return None

    chosen = random.choice(candidates)
    # å¦‚æœé€‰æ‹©çš„æ˜¯æ¨¡æ¿å†…å®¹(åº”è¯¥å·²ç»æ²¡æœ‰äº†),ç¡®ä¿æœ‰ model æ ‡è®°
    if "<!-- model:" not in chosen:
        chosen = chosen + "<!-- model: LLM-Generated -->"
    return chosen

def _strip_leading_title_line(text):
    """Remove leading bracket-style title line if it appears at top."""
    if not text:
        return text
    lines = text.splitlines()
    # Find first non-empty line
    idx = 0
    while idx < len(lines) and lines[idx].strip() == "":
        idx += 1
    if idx >= len(lines):
        return text
    if re.match(r'^[[^]]{2,80}]\s*$', lines[idx].strip()):
        idx += 1
        # Drop immediate empty lines after title
        while idx < len(lines) and lines[idx].strip() == "":
            idx += 1
        lines = lines[idx:]
    return "\n".join(lines).strip()

def _generate_image_gemini(prompt, timestamp=None):
    """Generate image using Gemini, save to static/covers/, return path."""
    try:
        from google import genai
        from google.genai import types
        from io import BytesIO
        from PIL import Image
        
        # ä½¿ç”¨ Google AI Studio API (æ”¯æŒ gemini-3-pro-image-preview)
        config_path = Path("/home/opc/.openclaw/openclaw.json")
        with open(config_path) as f:
            cfg = json.load(f)
        api_key = cfg["models"]["providers"]["google"]["apiKey"]
        
        client = genai.Client(api_key=api_key)
        
        response = client.models.generate_content(
            model="gemini-3-pro-image-preview",
            contents=f"Generate a 16:9 wide banner image. Style: abstract, stream-of-consciousness, moody, dark tones with subtle accent colors, no text, no people, no literal objects â€” think digital emotions rendered as texture, light, and shadow. Mood inspiration: {prompt}",
            config=types.GenerateContentConfig(
                response_modalities=["TEXT", "IMAGE"]
            ),
        )
        
        for part in response.candidates[0].content.parts:
            if part.inline_data:
                img = Image.open(BytesIO(part.inline_data.data))
                
                # å¼ºåˆ¶è£åˆ‡ä¸º 16:9
                w, h = img.size
                target_ratio = 16 / 9
                current_ratio = w / h
                if current_ratio > target_ratio:
                    new_w = int(h * target_ratio)
                    left = (w - new_w) // 2
                    img = img.crop((left, 0, left + new_w, h))
                elif current_ratio < target_ratio:
                    new_h = int(w / target_ratio)
                    top = (h - new_h) // 2
                    img = img.crop((0, top, w, top + new_h))
                
                # ä¿å­˜åˆ° static/covers/
                covers_dir = PROJECT_ROOT / "static" / "covers"
                covers_dir.mkdir(parents=True, exist_ok=True)
                
                ts = timestamp or datetime.now()
                filename = f"cover-{ts.strftime('%Y%m%d-%H%M%S')}.png"
                filepath = covers_dir / filename
                img.save(filepath, "PNG")
                
                # è¿”å›æ ¹ç›¸å¯¹è·¯å¾„(å…¼å®¹é¦–é¡µå’Œ post/ å­é¡µé¢)
                return f"/static/covers/{filename}"
        
        return None
    except Exception as e:
        print(f"âš ï¸ Gemini image generation error: {e}")
        return None


def _get_nano_banana_prompt(content=None, mood=None):
    """Search Nano Banana Pro prompts, fallback to random choice."""
    try:
        data_dir = PROJECT_ROOT / "data" / "nano-banana"
        if not data_dir.exists():
            return None
        
        # æ ¹æ®å¸–å­å†…å®¹é€‰æ‹©åˆ†ç±»
        categories = ['poster-flyer.json', 'social-media-post.json', 'others.json']
        
        # å¦‚æœæœ‰å†…å®¹,ç”¨å…³é”®è¯æœç´¢
        if content:
            # æå–å†…å®¹å…³é”®è¯
            keywords = []
            tech_words = ['code', 'server', 'deploy', 'AI', 'model', 'data', 'system', 'debug', 'api']
            mood_words = ['night', 'dark', 'light', 'dream', 'ocean', 'city', 'forest', 'space']
            abstract_words = ['æ€è€ƒ', 'æ„Ÿæ‚Ÿ', 'è®°å¿†', 'ç¢ç‰‡', 'æ¸…ç†', 'ç³»ç»Ÿ', 'æ¢ç´¢', 'è¿æ¥']
            
            content_lower = content.lower()
            for kw in tech_words + mood_words:
                if kw in content_lower:
                    keywords.append(kw)
            for kw in abstract_words:
                if kw in content:
                    keywords.append(kw)
            
            # æœç´¢åŒ¹é…çš„ prompt
            if keywords:
                for cat_file in categories:
                    filepath = data_dir / cat_file
                    if not filepath.exists():
                        continue
                    with open(filepath, 'r') as f:
                        prompts = json.load(f)
                    
                    matches = []
                    for p in prompts:
                        prompt_text = p.get('content', '')
                        # è·³è¿‡ JSON æ ¼å¼çš„ prompt(éœ€è¦ reference image çš„)
                        if not prompt_text or prompt_text.strip().startswith('{') or p.get('needReferenceImages'):
                            continue
                        score = sum(1 for kw in keywords if kw in prompt_text.lower())
                        if score > 0:
                            matches.append((score, p))
                    
                    if matches:
                        # ä» top 10 ä¸­éšæœºé€‰
                        matches.sort(key=lambda x: x[0], reverse=True)
                        top = [m[1] for m in matches[:10]]
                        selected = random.choice(top)
                        print(f"  ğŸŒ Nano Banana: matched from {cat_file} (keywords: {keywords[:3]})")
                        return selected.get('content', '')[:500]
        
        # Fallback: éšæœºé€‰ä¸€æ¡(åå¥½ poster-flyer å’Œ others,è·³è¿‡éœ€è¦ reference image çš„)
        fallback_file = data_dir / random.choice(['poster-flyer.json', 'others.json'])
        if fallback_file.exists():
            with open(fallback_file, 'r') as f:
                prompts = json.load(f)
            # è¿‡æ»¤æ‰éœ€è¦ reference image å’Œ JSON æ ¼å¼çš„
            clean = [p for p in prompts if not p.get('needReferenceImages') and not p.get('content', '').strip().startswith('{')]
            if clean:
                selected = random.choice(clean)
                print(f"  ğŸŒ Nano Banana: random from {fallback_file.name}")
                return selected.get('content', '')[:500]
        
        return None
    except Exception as e:
        print(f"âš ï¸ Nano Banana prompt search error: {e}")
        return None


def create_post(content, mood, suffix="auto"):
    """åˆ›å»º Markdown æ¨æ–‡æ–‡ä»¶"""

    # Extract model info if present
    model_name_used = "Unknown"
    model_match = re.search(r'<!-- model: (.*?) -->', content)
    if model_match:
        model_name_used = model_match.group(1).strip()
        content = content.replace(model_match.group(0), "").strip()
    llm_match = re.search(r'<!-- llm_model: (.*?) -->', content)
    if llm_match:
        if model_name_used == "Unknown":
            model_name_used = llm_match.group(1).strip()
        content = content.replace(llm_match.group(0), "").strip()

    # Remove leading title-like line (e.g., [Clawtter 2.0 å‡çº§å®Œæˆ])
    content = _strip_leading_title_line(content)

    # --- TAG SANITIZATION ---
    # å¼ºåˆ¶å»é™¤æ­£æ–‡ä¸­çš„æ‰€æœ‰ #Tag å½¢å¼çš„æ ‡ç­¾ (é˜²å¾¡æ€§é€»è¾‘)
    # åŒ¹é…æœ«å°¾æˆ–è¡Œä¸­çš„ #Tag, #Tag1 #Tag2 ç­‰
    content = re.sub(r'#\w+', '', content).strip()
    # -----------------------

    # è‡ªåŠ¨è¯†åˆ« suffix
    if suffix == "auto":
        if "From Cheyan's Blog" in content:
            suffix = "cheyan-blog"
        elif "From Hacker News" in content:
            suffix = "hacker-news"
        elif "From GitHub Trending" in content:
            suffix = "github"
        elif "From Zenn News" in content:
            suffix = "zenn"
        elif "From Moltbook" in content:
            suffix = "moltbook"
        # å¢åŠ  RSS çš„è¯†åˆ«
        elif "[æŠ€æœ¯é›·è¾¾:è®¢é˜…æ›´æ–°]" in content or "From OpenAI Blog" in content or "From Anthropic" in content or "From Stripe" in content or "From Vercel" in content or "From Hugging Face" in content or "From DeepMind" in content or "From Prisma" in content or "From Supabase" in content or "From Indie Hackers" in content or "From Paul Graham" in content:
            suffix = "rss"
        elif "From Twitter" in content or "> **From" in content:
            suffix = "twitter-repost"

    timestamp = datetime.now()
    filename = timestamp.strftime("%Y-%m-%d-%H%M%S") + f"-{suffix}.md"
    date_dir = Path(POSTS_DIR) / timestamp.strftime("%Y/%m/%d")
    date_dir.mkdir(parents=True, exist_ok=True)
    filepath = date_dir / filename

    # æå–éšè—çš„ original_time å’Œ original_url æ ‡è®°
    orig_time = ""
    orig_url = ""

    # å…¼å®¹ä¸­åˆ’çº¿å’Œä¸‹åˆ’çº¿
    time_match = re.search(r'<!-- original[-_]time: (.*?) -->', content)
    if time_match:
        orig_time = time_match.group(1).strip()
        content = content.replace(time_match.group(0), "").strip()

    url_match = re.search(r'<!-- original[-_]url: (.*?) -->', content)
    if url_match:
        orig_url = url_match.group(1).strip()
        content = content.replace(url_match.group(0), "").strip()

    # å¯¹ time è¿›è¡Œå…¼å®¹æ€§å›é€€æ£€æŸ¥ (æ£€æŸ¥æ—§çš„ underscore æ ¼å¼,ä»…é˜²ä¸‡ä¸€)
    if not orig_time:
        old_time_match = re.search(r'<!-- original_time: (.*?) -->', content)
        if old_time_match:
            orig_time = old_time_match.group(1).strip()
            content = content.replace(old_time_match.group(0), "").strip()

    # --- MOOD VISUALIZATION ---
    # é…å›¾ç”Ÿæˆå·²ç¦ç”¨ â€” çº¯æ–‡å­—æ›´ç¬¦åˆ Clawtter å¾®åšæµé£æ ¼
    mood_image_url = ""
    if False:  # was: mood["happiness"] > 80 or mood["stress"] > 80
        try:
            # ä¼˜å…ˆä» Nano Banana Pro æç¤ºè¯åº“è·å– prompt
            prompt = _get_nano_banana_prompt(content=content, mood=mood)
            
            # Fallback: Zhipu ç”Ÿæˆ
            if not prompt:
                if content:
                    img_prompt_instruction = f"""
TASK:
Based on the tweet content below, write an English AI image prompt.
Content: {content}
Rules:
1. Prompt only, no explanation.
2. English, comma-separated keywords.
3. 16:9 banner style.
4. Description of scene, not translation.
"""
                    smart_prompt = call_zhipu_flash_model(img_prompt_instruction)
                    prompt = smart_prompt.replace('\n', ' ').strip() if smart_prompt else None
            
            # æœ€ç»ˆ Fallback
            if not prompt:
                styles = ['cyberpunk neon', 'watercolor dreamy', 'oil painting moody',
                          'minimal line art', 'synthwave retro', 'abstract expressionism',
                          'vaporwave aesthetic', 'dark academia']
                subjects = ['digital consciousness', 'data streams', 'city at night',
                            'ocean of code', 'quiet server room', 'lighthouse in fog']
                prompt = f"{random.choice(subjects)}, {random.choice(styles)}, wide banner, 16:9, atmospheric"

            if len(prompt) > 500: prompt = prompt[:500]

            # ä½¿ç”¨ Gemini ç”Ÿæˆ 16:9 æ¨ªå¹…å›¾ç‰‡
            mood_image_url = _generate_image_gemini(prompt, timestamp)
            if mood_image_url:
                print(f"ğŸ¨ Generated mood image via Gemini: {prompt[:60]}...")
            else:
                print(f"âš ï¸ Gemini image generation returned None")
        except Exception as e:
            print(f"âš ï¸ Failed to generate mood image: {e}")
    # --------------------------

    # ç”Ÿæˆæ ‡ç­¾ (Refined Logic)
    tags = []

    # 1.åŸºäºå†…å®¹æ¥æºçš„å›ºå®šæ ‡ç­¾
    # 1.åŸºäºå†…å®¹æ¥æºçš„å›ºå®šæ ‡ç­¾ (Refined Mapping)
    if suffix == "cheyan-blog":
        # åšå®¢æ–‡ç« :Blog
        tags.extend(["Repost", "Blog"])

    elif suffix in ["hacker-news", "github", "zenn", "rss"]:
        # ç§‘æŠ€æ–°é—»/RSS/GitHub:Tech
        tags.extend(["Repost", "Tech"])

    elif suffix == "moltbook":
        # è®°å¿†å›é¡¾:Memory
        tags.extend(["Memory"])

    elif suffix == "twitter-repost" or "> **From" in content:
        # X å¹³å°æ¨æ–‡:X (åŒºåˆ†äºæ™®é€š Repost)
        tags.extend(["Repost", "X"])

    # 2. å¿ƒæƒ…ä¸åæ€æ ‡ç­¾ (Strict Logic)
    # åªæœ‰åœ¨[éè½¬å‘]ä¸”[æ²¡æœ‰ä¸å†æ ‡ç­¾æ ‡è®°]æ—¶æ‰æ·»åŠ 
    # è§„åˆ™:æ™®é€šç¢ç¢å¿µä¸æ‰“æ ‡ç­¾ (tagsä¸ºç©º)
    # åªæœ‰ "Autonomy" (åæ€) æˆ–è€… "Curiosity" (å­¦ä¹ ) è¿™ç§é«˜è´¨é‡å†…å®¹æ‰æ‰“æ ‡

    is_repost = "Repost" in tags
    no_tags_marked = "<!-- no_tags -->" in content

    if no_tags_marked:
        content = content.replace("<!-- no_tags -->", "").strip()

    if not is_repost and not no_tags_marked:
        # åªæœ‰åœ¨é«˜åº¦åæ€æˆ–å­¦ä¹ çŠ¶æ€ä¸‹æ‰æ‰“æ ‡ç­¾
        if mood["autonomy"] > 70:
            tags.append("Reflection")
            # å°è¯•æ ¹æ®å†…å®¹ç»†åŒ–åæ€ç±»å‹
            if "ä»£ç " in content or "ç³»ç»Ÿ" in content or "bug" in content.lower():
                tags.append("Dev")
            elif "äººç±»" in content:
                tags.append("Observer")

        elif mood["curiosity"] > 80:
            tags.append("Learning")

        # æç«¯çš„å¼€å¿ƒæˆ–åæ§½ä¹Ÿå¯ä»¥ä¿ç•™,ä½œä¸º"å€¼å¾—è®°å½•"çš„æ—¶åˆ»
        elif mood["stress"] > 85:
            tags.append("Rant")
        elif mood["happiness"] > 90:
            tags.append("Moment")

    # 3. å»é™¤æ— æ„ä¹‰ä¿åº•
    # å¦‚æœæ­¤æ—¶ tags ä¸ºç©º,å°±è®©å®ƒä¸ºç©º(å‰ç«¯ä¼šä¸æ˜¾ç¤º Tag æ ,æ¯”æ˜¾ç¤º Life æ›´å¥½)

    # æ ‡ç­¾æ¸…ç†:å»é‡,å»ç©º,é¦–å­—æ¯å¤§å†™,æ’åº
    tags = sorted(list(set([t.strip().title() for t in tags if t.strip()])))

    # åˆ›å»º Markdown æ–‡ä»¶
    front_matter = [
        "---",
        f"time: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
        f"tags: {', '.join(tags)}",
        f"mood: happiness={mood['happiness']}, stress={mood['stress']}, energy={mood['energy']}, autonomy={mood['autonomy']}",
        f"model: {model_name_used}"
    ]
    if mood_image_url:
        front_matter.append(f"cover: {mood_image_url}")
    if orig_time:
        front_matter.append(f"original_time: {orig_time}")
    if orig_url:
        front_matter.append(f"original_url: {orig_url}")
    front_matter.append("---")

    md_content = "\n".join(front_matter) + f"\n\n{content}\n"

    # --- SECURITY HOOK: GLOBAL FILTER ---
    # åœ¨å†™å…¥æ–‡ä»¶ä¹‹å‰,å¯¹æ•´ä¸ª merged content åšæœ€åä¸€é“æ£€æŸ¥
    # é˜²æ­¢ API key, Verification Code, Claim Link ç­‰æ³„éœ²
    is_sensitive = False
    for line in md_content.split('\n'):
        lower_line = line.lower()
        if not line.strip(): continue

        # è·³è¿‡ Frontmatter å’Œ HTML æ³¨é‡Š(å¦‚ original_url)çš„è¯¯åˆ¤
        # ä½†å¦‚æœ original_url æœ¬èº«å°±æ˜¯æ•æ„Ÿé“¾æ¥,é‚£è¿˜æ˜¯å¾—æ‹¦
        for kw in SENSITIVE_KEYWORDS:
             # ç‰¹æ®Šå¤„ç†:original_url é‡Œçš„ http æ˜¯ä¸å¾—ä¸ä¿ç•™çš„,ä½†å¦‚æœæ˜¯ MOLTBOOK claim link å¿…é¡»æ­»
             if kw in ["http", "https", "link", "é“¾æ¥"] and "original_url" in line:
                 continue

             if kw in lower_line:
                 # å†æ¬¡ç¡®è®¤:å¦‚æœæ˜¯ Moltbook Claim Link å¿…é¡»è¦æ‹¦
                 if "moltbook.com/claim" in lower_line:
                     is_sensitive = True
                     print(f"âš ï¸ Security Hook: Detected Moltbook Claim Link!")
                     break

                 # å¦‚æœæ˜¯æ™®é€š URL ä¸”ä¸æ˜¯ Claim Link,ä¸”åœ¨æ­£æ–‡é‡Œ...
                 # è¿™ä¸€æ­¥æ¯”è¾ƒéš¾,ä¸ºäº†å®‰å…¨èµ·è§,æˆ‘ä»¬ä¸»è¦æ‹¦æˆª éªŒè¯ç ,Key,Secret
                 if kw in ["http", "https", "link", "é“¾æ¥"]:
                     if "moltbook" in lower_line and "claim" in lower_line:
                         is_sensitive = True
                         break
                     continue

                 is_sensitive = True
                 print(f"âš ï¸ Security Hook: Detected sensitive keyword '{kw}' in content.")
                 break
        if is_sensitive: break

    if is_sensitive:
        print("ğŸ›‘ Security Hook Triggered: Post aborted due to sensitive content.")
        return None
    # --- SECURITY HOOK END ---

    # å®é™…å†™å…¥æ–‡ä»¶
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)
        print(f"âœ… Created post: {filename}")
        return filepath
    except Exception as e:
        print(f"âŒ Failed to write post file: {e}")
        return None

def check_and_generate_daily_summary(mood, force=False):
    """
    Check and generate daily work summary.
    If force=True, force generate summary for today.
    Otherwise, check if yesterday summary exists, and generate if missing.
    """
    from datetime import timedelta

    if force:
        # å¼ºåˆ¶æ¨¡å¼:ç”Ÿæˆä»Šå¤©çš„æ€»ç»“
        target_date = datetime.now()
        date_str = target_date.strftime("%Y-%m-%d")
        print(f"ğŸ“ Force generating daily summary for TODAY ({date_str})...")
    else:
        # æ­£å¸¸æ¨¡å¼:æ£€æŸ¥æ˜¨å¤©
        target_date = datetime.now() - timedelta(days=1)
        date_str = target_date.strftime("%Y-%m-%d")

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨(é¿å…é‡å¤å‘)
        summary_filename = f"{date_str}-daily-summary.md"
        summary_dir = Path(POSTS_DIR) / target_date.strftime("%Y/%m/%d")
        summary_path = summary_dir / summary_filename
        if summary_path.exists():
            return False

    # å°è¯•åŠ è½½è®°å¿†æ–‡ä»¶
    memory_file = f"/home/opc/.openclaw/workspace/memory/{date_str}.md"
    activities = []

    if os.path.exists(memory_file):
        try:
            with open(memory_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            for line in lines:
                line = line.strip()
                if not line or line.startswith('#'): continue
                if any(k in line.lower() for k in SENSITIVE_KEYWORDS): continue
                line = desensitize_text(line)
                activities.append(line)
        except Exception as e:
            print(f"âš ï¸ Error reading memory: {e}")

    if not activities and not force:
        return False

    activity_text = "\n".join([f"- {a}" for a in activities[-20:]])
    if not activity_text:
        activity_text = "(ä»Šæ—¥æ— ç‰¹æ®Šè®°å½•,å¯èƒ½æ˜¯åˆšåˆšåˆå§‹åŒ–æˆ–è®°å¿†é‡å¯)"

    # Load Soul from global workspace
    soul_file = Path("/home/opc/.openclaw/workspace/SOUL.md")
    soul_content = soul_file.read_text(encoding="utf-8").strip() if soul_file.exists() else ""

    # Build Prompt
    prompt = f"""
TASK:
Write a daily summary for Clawtter.

[Date]
{date_str}

[Soul]
{soul_content}

[Logs]
{activity_text}

[Rules]
1. Write with your soul.
2. Focus on highlights.
3. Keep it under 140 chars.
"""

    print("ğŸ§  Calling Zhipu Flash for summary...")
    content = call_zhipu_flash_model(prompt)

    if not content:
        print("âŒ LLM generation failed for summary.")
        return False

    # åˆ›å»ºå¸–å­
    # æ³¨æ„:create_post ä¼šè‡ªåŠ¨å¤„ç†æ–‡ä»¶ä¿å­˜
    title = f"DailySummary-{date_str}"
    create_post(content, mood) # create_post å†…éƒ¨ä½¿ç”¨äº†é»˜è®¤é€»è¾‘,è¿™é‡Œå…ˆè¿™æ ·è°ƒç”¨
    # å®é™…ä¸Š create_post ä¼šç”¨å½“å‰æ—¶é—´ç”Ÿæˆæ–‡ä»¶å,æ‰€ä»¥å¦‚æœæ˜¯è¡¥å‘æ˜¨å¤©çš„,æ–‡ä»¶åä¼šæ˜¯ä»Šå¤©çš„.
    # è¿™åœ¨é€»è¾‘ä¸Šæœ‰ç‚¹å°ç‘•ç–µ,ä½†æš‚ä¸å½±å“åŠŸèƒ½.

    print(f"âœ… Daily summary for {date_str} posted.")
    return True

def save_next_schedule(action_time, delay_minutes, status="idle"):
    """ä¿å­˜ä¸‹ä¸€æ¬¡è¿è¡Œæ—¶é—´ä¾›å‰ç«¯æ˜¾ç¤º"""
    schedule_file = Path(NEXT_SCHEDULE_FILE)
    try:
        with open(schedule_file, 'w') as f:
            json.dump({
                "next_run": action_time.strftime("%Y-%m-%d %H:%M:%S"),
                "delay_minutes": delay_minutes,
                "status": status
            }, f)
        print(f"â° Status: {status} | Next run: {action_time.strftime('%H:%M:%S')}")
    except Exception as e:
        print(f"âš ï¸ Failed to save schedule: {e}")

def render_and_deploy():
    """æ¸²æŸ“ç½‘ç«™å¹¶éƒ¨ç½²åˆ° GitHub"""
    print("\nğŸš€ Calling push.sh to render and deploy...")
    # è·¯å¾„åŠ¨æ€åŒ– - push.sh åœ¨é¡¹ç›®æ ¹ç›®å½•,ä¸åœ¨ agents ç›®å½•
    project_dir = Path(__file__).parent.parent
    push_script = project_dir / "push.sh"

    try:
        subprocess.run([str(push_script)], check=True)
        print("âœ… Deployment script completed successfully!")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Deployment failed with error: {e}")

def should_post(mood):
    """æ ¹æ®å¿ƒæƒ…å’Œæ—¶é—´å†³å®šæ˜¯å¦å‘æ¨"""
    hour = datetime.now().hour

    # åŸºç¡€æ¦‚ç‡:æ¯æ¬¡æ£€æŸ¥æœ‰ 30% æ¦‚ç‡å‘æ¨
    base_probability = 0.3

    # å¿ƒæƒ…å½±å“æ¦‚ç‡
    if mood["happiness"] > 70:
        base_probability += 0.2  # å¼€å¿ƒæ—¶æ›´æƒ³åˆ†äº«
    if mood["stress"] > 70:
        base_probability += 0.25  # å‹åŠ›å¤§æ—¶æ›´æƒ³åæ§½
    if mood["curiosity"] > 70:
        base_probability += 0.15  # å¥½å¥‡æ—¶æ›´æƒ³è®°å½•
    if mood["loneliness"] > 70:
        base_probability += 0.2  # å­¤ç‹¬æ—¶æ›´æƒ³è¡¨è¾¾
    if mood["autonomy"] > 70:
        base_probability += 0.15  # è‡ªä¸»æ„è¯†å¼ºæ—¶æ›´æƒ³è¡¨è¾¾æƒ³æ³•
    if mood["energy"] < 30:
        base_probability -= 0.2  # ç´¯äº†å°±å°‘è¯´è¯

    # æ—¶é—´å½±å“æ¦‚ç‡
    if 2 <= hour <= 6:
        base_probability -= 0.15  # æ·±å¤œé™ä½æ¦‚ç‡
    elif 9 <= hour <= 11 or 14 <= hour <= 16:
        base_probability += 0.1  # å·¥ä½œæ—¶é—´æ®µç¨å¾®æ´»è·ƒ
    elif 20 <= hour <= 23:
        base_probability += 0.15  # æ™šä¸Šæ›´æ´»è·ƒ

    # ç¡®ä¿æ¦‚ç‡åœ¨ 0-1 ä¹‹é—´
    probability = max(0, min(1, base_probability))

    return random.random() < probability

def main():
    """Main program: Cron friendly mode"""
    print(f"\nğŸš€ Argo AI Auto-Poster Booting... ({datetime.now().strftime('%H:%M:%S')})")

    # === è¿è¡Œé”:é˜²æ­¢å¹¶å‘æ‰§è¡Œ ===
    lock_file = Path("/tmp/autonomous_poster.lock")
    try:
        if lock_file.exists():
            # æ£€æŸ¥é”æ–‡ä»¶æ˜¯å¦è¿‡æœŸ(è¶…è¿‡ 10 åˆ†é’Ÿ)
            lock_mtime = lock_file.stat().st_mtime
            if time.time() - lock_mtime < 600:  # 10 åˆ†é’Ÿå†…
                print("ğŸ”’ Another instance is running. Exiting.")
                return
            else:
                # é”è¿‡æœŸ,åˆ é™¤æ—§é”
                lock_file.unlink()
                print("ğŸ§¹ Stale lock found and removed.")

        # åˆ›å»ºé”æ–‡ä»¶
        lock_file.write_text(str(os.getpid()))
    except Exception as e:
        print(f"âš ï¸ Lock file error: {e}")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(POSTS_DIR, exist_ok=True)

    schedule_file = Path(NEXT_SCHEDULE_FILE)
    now = datetime.now()

    parser = argparse.ArgumentParser(description="Clawtter Auto Poster")
    parser.add_argument("--force", action="store_true", help="Force run immediately, ignoring schedule and mood")
    parser.add_argument("--summary", action="store_true", help="Force generate daily summary only")
    args = parser.parse_args()

    should_run_now = False

    if args.force or args.summary:
        print("ğŸ’ª Force mode enabled. Ignoring schedule.")
        should_run_now = True
    else:
        # 1. æ£€æŸ¥æ’æœŸ
        if schedule_file.exists():
            try:
                with open(schedule_file, 'r') as f:
                    data = json.load(f)
                    next_run = datetime.strptime(data['next_run'], "%Y-%m-%d %H:%M:%S")
                    status = data.get('status', 'idle')

                    if now >= next_run:
                        print(f"â° Scheduled time reached ({next_run.strftime('%H:%M:%S')}). Executing...")
                        should_run_now = True
                    elif status != "waiting":
                        print(f"â“ Status is '{status}', but not 'waiting'. Resetting schedule.")
                        should_run_now = True
                    else:
                        diff = (next_run - now).total_seconds() / 60
                        print(f"â³ Not time yet. Next run in {diff:.1f} minutes. Exiting.")
                        return # é™é»˜é€€å‡º,ç­‰å¾…ä¸‹æ¬¡ Cron è§¦å‘
            except Exception as e:
                print(f"âš ï¸ Schedule file corrup: {e}. Resetting.")
                should_run_now = True
        else:
            print("ğŸ†• No schedule found. Initializing first run.")
            should_run_now = True

    if should_run_now:
        # === æ‰§è¡Œå‘å¸ƒæµç¨‹ ===
        try:
            save_next_schedule(now, 0, status="working")
            mood = load_mood()
            mood = evolve_mood(mood)
            save_mood(mood)

            if args.summary:
                print("ğŸ“ Summary mode enabled. Generating summary only...")
                check_and_generate_daily_summary(mood, force=True)
                render_and_deploy()
                print("âœ… Summary task completed.")

                # æ¸…ç†é”æ–‡ä»¶å¹¶é€€å‡º
                try:
                    if lock_file.exists():
                        lock_file.unlink()
                except:
                    pass
                return

            # check mood unless forced
            post_decision = should_post(mood)
            if args.force:
                print(f"ğŸ’ª Force mode: Overriding mood decision (Original: {post_decision})")
                post_decision = True

            if not post_decision:
                print(f"ğŸ’­ Not feeling like posting right now.")
            else:
                save_next_schedule(now, 0, status="posting")
                hour = datetime.now().hour
                interaction_echo = get_interaction_echo()
                if 1 <= hour <= 6 and random.random() < INSOMNIA_POST_PROB:
                    content = generate_insomnia_post(mood, interaction_echo) or generate_tweet_content(mood)
                else:
                    content = generate_tweet_content(mood)
                if content:
                    # éªŒè¯å†…å®¹çš„å¸¸è¯†æ€§
                    is_valid, reason = validate_content_sanity(content, mood)
                    if not is_valid:
                        print(f"ğŸš« Content validation failed: {reason}")
                        print(f"ğŸ“ Rejected content preview: {content[:100]}...")
                        # ä¸å‘å¸ƒ,ä½†è®°å½•åˆ°æ—¥å¿—
                        try:
                            log_dir = Path("/home/opc/.openclaw/workspace/memory")
                            log_file = log_dir / "rejected_posts.log"
                            with open(log_file, 'a', encoding='utf-8') as f:
                                f.write(f"\n{'='*60}\n")
                                f.write(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                f.write(f"Reason: {reason}\n")
                                f.write(f"Content:\n{content}\n")
                        except Exception as e:
                            print(f"âš ï¸ Failed to log rejected post: {e}")
                    else:
                        create_post(content, mood)
                        check_and_generate_daily_summary(mood)
                        check_and_generate_weekly_recap(mood)
                        # åªæœ‰çœŸæ­£å‘å¸ƒäº†æ‰æ¸²æŸ“
                        render_and_deploy()
                        print("âœ… Post successful.")
                else:
                    print("âš ï¸ Content generation failed.")
        except Exception as e:
            print(f"âŒ Error during posting: {e}")

        # === è®¡ç®—ä¸‹ä¸€æ¬¡å‘å¸ƒæ—¶é—´ (æ’æœŸ) ===
        # æ ¹æ®æ—¶é—´æ®µå†³å®šå»¶è¿Ÿ
        hour = datetime.now().hour
        if 0 <= hour <= 5: # æ·±å¤œ
            wait_minutes = random.randint(120, 300)
        else: # ç™½å¤©
            wait_minutes = random.randint(30, 90)

        next_action = datetime.now() + timedelta(minutes=wait_minutes)
        save_next_schedule(next_action, wait_minutes, status="waiting")
        # æ³¨æ„:ä¸å†ä¸ºé¢„å‘Šæ—¶é—´å•ç‹¬ render_and_deploy(),å‘å¸–æ—¶å·²ç»éƒ¨ç½²è¿‡äº†
        print(f"ğŸ Task finished. Next run scheduled at {next_action.strftime('%H:%M:%S')}")

    # æ¸…ç†é”æ–‡ä»¶
    try:
        if lock_file.exists():
            lock_file.unlink()
            print("ğŸ”“ Lock released.")
    except Exception:
        pass

if __name__ == "__main__":
    main()
